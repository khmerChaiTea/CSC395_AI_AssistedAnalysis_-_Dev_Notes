{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3a32f3c7",
   "metadata": {},
   "source": [
    "# Import numpy with alias np\n",
    "import numpy as np\n",
    "\n",
    "# Filter for Belgium\n",
    "be_consumption = food_consumption[food_consumption['country'] == 'Belgium']\n",
    "\n",
    "# Filter for USA\n",
    "usa_consumption = food_consumption[food_consumption['country'] == 'USA']\n",
    "\n",
    "# Calculate mean and median consumption in Belgium\n",
    "print(np.mean(be_consumption['consumption']))\n",
    "print(np.median(be_consumption['consumption']))\n",
    "\n",
    "# Calculate mean and median consumption in USA\n",
    "print(np.mean(usa_consumption['consumption']))\n",
    "print(np.median(usa_consumption['consumption']))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e73c1c8",
   "metadata": {},
   "source": [
    "42.13272727272727\n",
    "12.59\n",
    "44.650000000000006\n",
    "14.58"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f3f030d0",
   "metadata": {},
   "source": [
    "# Import numpy as np\n",
    "import numpy as np\n",
    "\n",
    "# Subset for Belgium and USA only\n",
    "be_and_usa = food_consumption[(food_consumption['country'] == \"Belgium\") | (food_consumption['country'] == 'USA')]\n",
    "\n",
    "# Group by country, select consumption column, and compute mean and median\n",
    "print(be_and_usa.groupby('country')['consumption'].agg([np.mean, np.median]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a48281c0",
   "metadata": {},
   "source": [
    "           mean  median\n",
    "country                \n",
    "Belgium  42.133   12.59\n",
    "USA      44.650   14.58"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc583039",
   "metadata": {},
   "source": [
    "# Import matplotlib.pyplot with alias plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Subset for food_category equals rice\n",
    "rice_consumption = food_consumption[food_consumption['food_category'] == 'rice']\n",
    "\n",
    "# Histogram of co2_emission for rice and show plot\n",
    "plt.hist(rice_consumption['co2_emission'], bins=10, edgecolor='black')  # Adjust bins as needed\n",
    "plt.title('Histogram of CO2 Emission for Rice')\n",
    "plt.xlabel('CO2 Emission (kg CO2 per person per year)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d951c053",
   "metadata": {},
   "source": [
    "# Subset for food_category equals rice\n",
    "rice_consumption = food_consumption[food_consumption['food_category'] == 'rice']\n",
    "\n",
    "# Calculate mean and median of co2_emission with .agg()\n",
    "mean_co2 = rice_consumption['co2_emission'].agg('mean')\n",
    "median_co2 = rice_consumption['co2_emission'].agg('median')\n",
    "print(mean_co2)\n",
    "print(median_co2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f0a98c0",
   "metadata": {},
   "source": [
    "37.59161538461538\n",
    "15.2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6591f529",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate the quartiles of co2_emission\n",
    "print(np.quantile(food_consumption['co2_emission'], [0, 0.25, 0.5, 0.75, 1]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b0dd3c8",
   "metadata": {},
   "source": [
    "[   0.        5.21     16.53     62.5975 1712.    ]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "939d9986",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate the quintiles of co2_emission\n",
    "quintiles = np.quantile(food_consumption['co2_emission'], [0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "print(quintiles)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2ddd631",
   "metadata": {},
   "source": [
    "[   0.       3.54    11.026   25.59    99.978 1712.   ]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c958c977",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate the deciles of co2_emission\n",
    "print(np.quantile(food_consumption['co2_emission'], np.linspace(0, 1, 11)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e111fe63",
   "metadata": {},
   "source": [
    "[0.00000e+00 6.68000e-01 3.54000e+00 7.04000e+00 1.10260e+01 1.65300e+01\n",
    " 2.55900e+01 4.42710e+01 9.99780e+01 2.03629e+02 1.71200e+03]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3feac88e",
   "metadata": {},
   "source": [
    "# Print variance and sd of co2_emission for each food_category\n",
    "print(food_consumption.groupby('food_category')['co2_emission'].agg(['var', 'std']))\n",
    "\n",
    "# Import matplotlib.pyplot with alias plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create histogram of co2_emission for food_category 'beef'\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(food_consumption[food_consumption['food_category'] == 'beef']['co2_emission'], bins=20, edgecolor='black')\n",
    "plt.title('Histogram of CO2 Emission for Beef')\n",
    "plt.xlabel('CO2 Emission (kg CO2 per person per year)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Create histogram of co2_emission for food_category 'eggs'\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(food_consumption[food_consumption['food_category'] == 'eggs']['co2_emission'], bins=20, edgecolor='black')\n",
    "plt.title('Histogram of CO2 Emission for Eggs')\n",
    "plt.xlabel('CO2 Emission (kg CO2 per person per year)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95dc4fd0",
   "metadata": {},
   "source": [
    "# Group by 'country' and sum 'co2_emission'\n",
    "emissions_by_country = food_consumption.groupby('country')['co2_emission'].sum()\n",
    "\n",
    "print(emissions_by_country)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b7f4c26f",
   "metadata": {},
   "source": [
    "country\n",
    "Albania      1777.85\n",
    "Algeria       707.88\n",
    "Angola        412.99\n",
    "Argentina    2172.40\n",
    "Armenia      1109.93\n",
    "              ...   \n",
    "Uruguay      1634.91\n",
    "Venezuela    1104.10\n",
    "Vietnam       641.51\n",
    "Zambia        225.30\n",
    "Zimbabwe      350.33\n",
    "Name: co2_emission, Length: 130, dtype: float64"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b7198e4",
   "metadata": {},
   "source": [
    "# Calculate total co2_emission per country: emissions_by_country\n",
    "emissions_by_country = food_consumption.groupby('country')['co2_emission'].sum()\n",
    "\n",
    "# Compute the first and third quartiles and IQR of emissions_by_country\n",
    "q1 = np.quantile(emissions_by_country, 0.25)\n",
    "q3 = np.quantile(emissions_by_country, 0.75)\n",
    "iqr = q3 - q1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12f81ab0",
   "metadata": {},
   "source": [
    "# Calculate total co2_emission per country: emissions_by_country\n",
    "emissions_by_country = food_consumption.groupby('country')['co2_emission'].sum()\n",
    "\n",
    "# Compute the first and third quantiles and IQR of emissions_by_country\n",
    "q1 = np.quantile(emissions_by_country, 0.25)\n",
    "q3 = np.quantile(emissions_by_country, 0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "# Calculate the lower and upper cutoffs for outliers\n",
    "lower = q1 - 1.5 * iqr\n",
    "upper = q3 + 1.5 * iqr"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d8b2938d",
   "metadata": {},
   "source": [
    "# Calculate total co2_emission per country: emissions_by_country\n",
    "emissions_by_country = food_consumption.groupby('country')['co2_emission'].sum()\n",
    "\n",
    "# Compute the first and third quantiles and IQR of emissions_by_country\n",
    "q1 = np.quantile(emissions_by_country, 0.25)\n",
    "q3 = np.quantile(emissions_by_country, 0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "# Calculate the lower and upper cutoffs for outliers\n",
    "lower = q1 - 1.5 * iqr\n",
    "upper = q3 + 1.5 * iqr\n",
    "\n",
    "# Subset emissions_by_country to find outliers\n",
    "outliers = emissions_by_country[(emissions_by_country < lower) | (emissions_by_country > upper)]\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6bad09ee",
   "metadata": {},
   "source": [
    "country\n",
    "Argentina    2172.4\n",
    "Name: co2_emission, dtype: float64"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dea467ff",
   "metadata": {},
   "source": [
    "# Try using value_counts() on the 'product' column\n",
    "counts = amir_deals['product'].value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c86d203e",
   "metadata": {},
   "source": [
    "Product B    62\n",
    "Product D    40\n",
    "Product A    23\n",
    "Product C    15\n",
    "Product F    11\n",
    "Product H     8\n",
    "Product I     7\n",
    "Product E     5\n",
    "Product N     3\n",
    "Product G     2\n",
    "Product J     2\n",
    "Name: product, dtype: int64"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c992d7e",
   "metadata": {},
   "source": [
    "# Count the deals for each product\n",
    "counts = amir_deals['product'].value_counts()\n",
    "\n",
    "# Calculate probability of picking a deal with each product\n",
    "probs = counts / counts.sum()\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cdb0a81c",
   "metadata": {},
   "source": [
    "Product B    0.348\n",
    "Product D    0.225\n",
    "Product A    0.129\n",
    "Product C    0.084\n",
    "Product F    0.062\n",
    "Product H    0.045\n",
    "Product I    0.039\n",
    "Product E    0.028\n",
    "Product N    0.017\n",
    "Product G    0.011\n",
    "Product J    0.011\n",
    "Name: product, dtype: float64"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aae8807c",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(24)\n",
    "\n",
    "# Sample 5 deals without replacement\n",
    "sample_without_replacement = amir_deals.sample(n=5, replace=False)\n",
    "print(sample_without_replacement)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "749928da",
   "metadata": {},
   "source": [
    "     Unnamed: 0    product   client status   amount  num_users\n",
    "127         128  Product B  Current    Won  2070.25          7\n",
    "148         149  Product D  Current    Won  3485.48         52\n",
    "77           78  Product B  Current    Won  6252.30         27\n",
    "104         105  Product D  Current    Won  4110.98         39\n",
    "166         167  Product C      New   Lost  3779.86         11"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc3e31b2",
   "metadata": {},
   "source": [
    "# Set random seed\n",
    "np.random.seed(24)\n",
    "\n",
    "# Sample 5 deals with replacement\n",
    "sample_with_replacement = amir_deals.sample(n=5, replace=True)\n",
    "print(sample_with_replacement)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "609a6759",
   "metadata": {},
   "source": [
    "     Unnamed: 0    product   client status   amount  num_users\n",
    "162         163  Product D  Current    Won  6755.66         59\n",
    "131         132  Product B  Current    Won  6872.29         25\n",
    "87           88  Product C  Current    Won  3579.63          3\n",
    "145         146  Product A  Current    Won  4682.94         63\n",
    "145         146  Product A  Current    Won  4682.94         63"
   ]
  },
  {
   "cell_type": "raw",
   "id": "888f7458",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a histogram of restaurant_groups and show plot\n",
    "# Assuming restaurant_groups is already defined\n",
    "restaurant_groups['group_size'].hist(bins=[2, 3, 4, 5, 6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "503c06b6",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming restaurant_groups DataFrame is already defined and has a column 'group_size'\n",
    "restaurant_groups['group_size'].hist(bins=[2, 3, 4, 5, 6])\n",
    "\n",
    "plt.xlabel('Group Size')  # Set label for x-axis\n",
    "plt.ylabel('Frequency')   # Set label for y-axis\n",
    "plt.title('Distribution of Group Sizes')  # Set title for the plot\n",
    "\n",
    "plt.grid(True)  # Optional: Add grid lines for better readability\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c932943b",
   "metadata": {},
   "source": [
    "# Create probability distribution\n",
    "size_dist = restaurant_groups['group_size'].value_counts() / len(restaurant_groups)\n",
    "\n",
    "# Reset index and rename columns\n",
    "size_dist = size_dist.reset_index()\n",
    "size_dist.columns = ['group_size', 'prob']\n",
    "\n",
    "print(size_dist)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "972f2eab",
   "metadata": {},
   "source": [
    "   group_size  prob\n",
    "0           2   0.6\n",
    "1           4   0.2\n",
    "2           6   0.1\n",
    "3           3   0.1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "28519c11",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming restaurant_groups DataFrame is defined and has a column 'group_size'\n",
    "# Calculate the probability distribution of group sizes\n",
    "size_dist = restaurant_groups['group_size'].value_counts() / restaurant_groups.shape[0]\n",
    "\n",
    "# Reset index and rename columns\n",
    "size_dist = size_dist.reset_index()\n",
    "size_dist.columns = ['group_size', 'prob']\n",
    "\n",
    "# Calculate expected value\n",
    "expected_value = (size_dist['group_size'] * size_dist['prob']).sum()\n",
    "print(f\"Expected group size: {expected_value}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37d2777c",
   "metadata": {},
   "source": [
    "Expected group size: 2.9000000000000004"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c384383f",
   "metadata": {},
   "source": [
    "# Create probability distribution\n",
    "size_dist = restaurant_groups['group_size'].value_counts() / restaurant_groups.shape[0]\n",
    "# Reset index and rename columns\n",
    "size_dist = size_dist.reset_index()\n",
    "size_dist.columns = ['group_size', 'prob']\n",
    "\n",
    "# Expected value\n",
    "expected_value = np.sum(size_dist['group_size'] * size_dist['prob'])\n",
    "\n",
    "# Subset groups of size 4 or more\n",
    "groups_4_or_more = ____\n",
    "\n",
    "# Sum the probabilities of groups_4_or_more\n",
    "prob_4_or_more = ____\n",
    "print(prob_4_or_more)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f413d5b0",
   "metadata": {},
   "source": [
    "# Create probability distribution\n",
    "size_dist = restaurant_groups['group_size'].value_counts() / restaurant_groups.shape[0]\n",
    "# Reset index and rename columns\n",
    "size_dist = size_dist.reset_index()\n",
    "size_dist.columns = ['group_size', 'prob']\n",
    "\n",
    "# Expected value\n",
    "expected_value = np.sum(size_dist['group_size'] * size_dist['prob'])\n",
    "\n",
    "# Subset groups of size 4 or more\n",
    "groups_4_or_more = size_dist[size_dist['group_size'] >= 4]\n",
    "\n",
    "# Sum the probabilities of groups_4_or_more\n",
    "prob_4_or_more = groups_4_or_more['prob'].sum()\n",
    "print(prob_4_or_more)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1cfdab9",
   "metadata": {},
   "source": [
    "0.30000000000000004"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1bc4d94",
   "metadata": {},
   "source": [
    "# Min and max wait times for back-up that happens every 30 min\n",
    "min_time = 0\n",
    "max_time = 30"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70b2fd28",
   "metadata": {},
   "source": [
    "# Min and max wait times for back-up that happens every 30 min\n",
    "min_time = 0\n",
    "max_time = 30\n",
    "\n",
    "# Import uniform from scipy.stats\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Calculate probability of waiting less than 5 mins\n",
    "prob_less_than_5 = uniform.cdf(5, loc=min_time, scale=max_time - min_time)\n",
    "print(prob_less_than_5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bfef2802",
   "metadata": {},
   "source": [
    "0.16666666666666666"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7bfd40fa",
   "metadata": {},
   "source": [
    "# Min and max wait times for back-up that happens every 30 min\n",
    "min_time = 0\n",
    "max_time = 30\n",
    "\n",
    "# Import uniform from scipy.stats\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Calculate probability of waiting more than 5 mins\n",
    "prob_greater_than_5 = 1 - uniform.cdf(5, loc=min_time, scale=max_time - min_time)\n",
    "print(prob_greater_than_5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ef2317b",
   "metadata": {},
   "source": [
    "0.8333333333333334"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5419ec69",
   "metadata": {},
   "source": [
    "# Min and max wait times for back-up that happens every 30 min\n",
    "min_time = 0\n",
    "max_time = 30\n",
    "\n",
    "# Import uniform from scipy.stats\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Calculate probability of waiting 10-20 mins\n",
    "prob_between_10_and_20 = uniform.cdf(20, loc=min_time, scale=max_time - min_time) - uniform.cdf(10, loc=min_time, scale=max_time - min_time)\n",
    "print(prob_between_10_and_20)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b5f3050",
   "metadata": {},
   "source": [
    "0.3333333333333333"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3867c879",
   "metadata": {},
   "source": [
    "# Set random seed to 334\n",
    "np.random.seed(334)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9bd270d3",
   "metadata": {},
   "source": [
    "# Set random seed to 334\n",
    "np.random.seed(334)\n",
    "\n",
    "# Import uniform\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b4dd8f63",
   "metadata": {},
   "source": [
    "# Set random seed to 334\n",
    "np.random.seed(334)\n",
    "\n",
    "# Import uniform\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Generate 1000 wait times between 0 and 30 mins\n",
    "wait_times = uniform.rvs(loc=0, scale=30, size=1000)\n",
    "\n",
    "print(wait_times)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6697f8fa",
   "metadata": {},
   "source": [
    "# Set random seed to 334\n",
    "np.random.seed(334)\n",
    "\n",
    "# Import uniform\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Generate 1000 wait times between 0 and 30 mins\n",
    "wait_times = uniform.rvs(0, 30, size=1000)\n",
    "\n",
    "# Create a histogram of simulated times and show plot\n",
    "plt.hist(wait_times)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "053be951",
   "metadata": {},
   "source": [
    "# Import binom from scipy.stats\n",
    "from scipy.stats import binom\n",
    "\n",
    "# Set random seed to 10\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e50f5aa4",
   "metadata": {},
   "source": [
    "# Import binom from scipy.stats\n",
    "from scipy.stats import binom\n",
    "\n",
    "# Set random seed to 10\n",
    "np.random.seed(10)\n",
    "\n",
    "# Simulate a single deal\n",
    "print(binom.rvs(1, 0.3, size=1))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9806f01",
   "metadata": {},
   "source": [
    "[1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43a80e34",
   "metadata": {},
   "source": [
    "# Import binom from scipy.stats\n",
    "from scipy.stats import binom\n",
    "\n",
    "# Set random seed to 10\n",
    "np.random.seed(10)\n",
    "\n",
    "# Simulate 1 week of 3 deals\n",
    "print(binom.rvs(3, .3, size=1))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f6bdf8e",
   "metadata": {},
   "source": [
    "[1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c81b45a5",
   "metadata": {},
   "source": [
    "# Import binom from scipy.stats\n",
    "from scipy.stats import binom\n",
    "\n",
    "# Set random seed to 10\n",
    "np.random.seed(10)\n",
    "\n",
    "# Simulate 52 weeks of 3 deals\n",
    "deals = binom.rvs(3, .3, size=52)\n",
    "\n",
    "# Print mean deals won per week\n",
    "print(np.mean(deals))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "af27e7f9",
   "metadata": {},
   "source": [
    "0.8269230769230769"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c44883cf",
   "metadata": {},
   "source": [
    "# Probability of closing 3 out of 3 deals\n",
    "prob_3 = binom.pmf(3, 3, 0.3)\n",
    "\n",
    "print(prob_3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f163e586",
   "metadata": {},
   "source": [
    "0.026999999999999996"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4fc7bbcd",
   "metadata": {},
   "source": [
    "# Probability of closing <= 1 deal out of 3 deals\n",
    "prob_less_than_or_equal_1 = binom.cdf(1, 3, 0.3)\n",
    "\n",
    "print(prob_less_than_or_equal_1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b6d983b",
   "metadata": {},
   "source": [
    "0.784"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8713d843",
   "metadata": {},
   "source": [
    "# Probability of closing > 1 deal out of 3 deals\n",
    "# Calculate the probability of closing 1 or fewer deals\n",
    "prob_less_than_or_equal_1 = binom.cdf(1, 3, 0.3)\n",
    "\n",
    "# Subtract from 1 to get the probability of closing more than 1 deal\n",
    "prob_greater_than_1 = 1 - prob_less_than_or_equal_1\n",
    "\n",
    "print(prob_greater_than_1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6302eff6",
   "metadata": {},
   "source": [
    "0.21599999999999997"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4144d238",
   "metadata": {},
   "source": [
    "# Expected number won with 30% win rate\n",
    "won_30pct = 3 * 0.3\n",
    "print(won_30pct)\n",
    "\n",
    "# Expected number won with 25% win rate\n",
    "won_25pct = 3 * 0.25\n",
    "print(won_25pct)\n",
    "\n",
    "# Expected number won with 35% win rate\n",
    "won_35pct = 3 * 0.35\n",
    "print(won_35pct)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b1f1bf2",
   "metadata": {},
   "source": [
    "0.8999999999999999\n",
    "0.75\n",
    "1.0499999999999998"
   ]
  },
  {
   "cell_type": "raw",
   "id": "68f14d13",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Histogram of amount with 10 bins and show plot\n",
    "# Create a histogram of 'amount' column with 10 bins\n",
    "plt.figure(figsize=(8, 6))\n",
    "amir_deals['amount'].hist(bins=10, edgecolor='black')\n",
    "plt.title('Distribution of Amir\\'s Sales Amounts')\n",
    "plt.xlabel('Amount')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2572cd5",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Probability of deal < 7500\n",
    "prob_less_7500 = norm.cdf(7500, loc=mean_amount, scale=std_dev_amount)\n",
    "\n",
    "print(prob_less_7500)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b52a334",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Probability of deal < 7500\n",
    "prob_less_7500 = norm.cdf(7500, 5000, 2000)\n",
    "\n",
    "print(prob_less_7500)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "93ce5da8",
   "metadata": {},
   "source": [
    "0.8943502263331446"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ab6a7d4",
   "metadata": {},
   "source": [
    "# Probability of deal > 1000\n",
    "prob_over_1000 = 1 - norm.cdf(1000, 5000, 2000)\n",
    "\n",
    "print(prob_over_1000)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d27c123",
   "metadata": {},
   "source": [
    "0.9772498680518208"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e66170b",
   "metadata": {},
   "source": [
    "# Probability of deal between 3000 and 7000\n",
    "prob_3000_to_7000 = norm.cdf(7000, 5000, 2000) - norm.cdf(3000, 5000, 2000)\n",
    "\n",
    "print(prob_3000_to_7000)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "913e2282",
   "metadata": {},
   "source": [
    "0.6826894921370859"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e74602b5",
   "metadata": {},
   "source": [
    "# Calculate amount that 25% of deals will be less than\n",
    "pct_25 = norm.ppf(0.25, 5000, 2000)\n",
    "\n",
    "print(pct_25)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "63d2c08d",
   "metadata": {},
   "source": [
    "3651.0204996078364"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a5a526ee",
   "metadata": {},
   "source": [
    "# Calculate new average amount\n",
    "new_mean = 5000 * 1.20\n",
    "\n",
    "# Calculate new standard deviation\n",
    "new_sd = 2000 * 1.30\n",
    "\n",
    "# Simulate 36 new sales\n",
    "new_sales = norm.rvs(new_mean, new_sd, size=36)\n",
    "\n",
    "# Create histogram and show\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(new_sales, bins=10, edgecolor='black')\n",
    "plt.title('Distribution of New Sales Amounts')\n",
    "plt.xlabel('Amount')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2cbd05a",
   "metadata": {},
   "source": [
    "# Create a histogram of num_users and show\n",
    "amir_deals['num_users'].hist(bins=30, edgecolor='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd0ffaa9",
   "metadata": {},
   "source": [
    "# Set seed to 104\n",
    "np.random.seed(104)\n",
    "\n",
    "# Sample 20 num_users with replacement from amir_deals\n",
    "samp_20 = np.random.choice(amir_deals['num_users'], size=20, replace=True)\n",
    "\n",
    "# Take mean of samp_20\n",
    "print(np.mean(samp_20))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d77104ab",
   "metadata": {},
   "source": [
    "32.0"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50072f0c",
   "metadata": {},
   "source": [
    "# Set seed to 104\n",
    "np.random.seed(104)\n",
    "\n",
    "# Sample 20 num_users with replacement from amir_deals and take mean\n",
    "samp_20 = amir_deals['num_users'].sample(20, replace=True)\n",
    "np.mean(samp_20)\n",
    "\n",
    "sample_means = []\n",
    "# Loop 100 times\n",
    "for i in range(100):\n",
    "  # Take sample of 20 num_users\n",
    "  samp_20 = amir_deals['num_users'].sample(20, replace=True)\n",
    "  # Calculate mean of samp_20\n",
    "  samp_20_mean = np.mean(samp_20)\n",
    "  # Append samp_20_mean to sample_means\n",
    "  sample_means.append(samp_20_mean)\n",
    "  \n",
    "print(sample_means)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9cdbc21b",
   "metadata": {},
   "source": [
    "[31.35, 45.05, 33.55, 38.15, 50.85, 31.85, 34.65, 36.25, 38.9, 44.05, 35.45, 37.6, 37.95, 28.85, 33.3, 31.65, 45.5, 43.2, 24.4, 41.05, 37.2, 39.3, 29.45, 33.55, 45.3, 45.1, 30.95, 36.25, 37.65, 42.55, 34.55, 41.1, 36.9, 42.45, 38.45, 45.9, 42.7, 38.4, 32.55, 30.25, 38.0, 38.75, 49.3, 39.55, 49.05, 42.05, 41.0, 40.6, 58.25, 34.55, 51.2, 34.15, 36.95, 42.45, 41.85, 33.2, 36.15, 37.55, 34.2, 29.75, 42.35, 43.75, 29.0, 32.05, 31.65, 44.6, 30.85, 29.6, 37.7, 33.1, 36.35, 40.65, 45.7, 33.8, 40.1, 39.9, 33.5, 32.65, 32.85, 42.85, 35.4, 31.7, 32.0, 33.85, 36.6, 44.35, 39.9, 37.0, 37.3, 42.5, 38.35, 42.8, 44.55, 30.3, 50.45, 42.35, 40.65, 29.85, 39.3, 33.1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a6389e6",
   "metadata": {},
   "source": [
    "# Set seed to 104\n",
    "np.random.seed(104)\n",
    "\n",
    "sample_means = []\n",
    "# Loop 100 times\n",
    "for i in range(100):\n",
    "  # Take sample of 20 num_users\n",
    "  samp_20 = amir_deals['num_users'].sample(20, replace=True)\n",
    "  # Calculate mean of samp_20\n",
    "  samp_20_mean = np.mean(samp_20)\n",
    "  # Append samp_20_mean to sample_means\n",
    "  sample_means.append(samp_20_mean)\n",
    "  \n",
    "# Convert to Series and plot histogram\n",
    "sample_means_series = pd.Series(sample_means)\n",
    "sample_means_series.hist(bins=20, edgecolor='black')\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e369cdb9",
   "metadata": {},
   "source": [
    "# Set seed to 321\n",
    "np.random.seed(321)\n",
    "\n",
    "sample_means = []\n",
    "# Loop 30 times to take 30 means\n",
    "for i in range(30):\n",
    "  # Take sample of size 20 from num_users col of all_deals with replacement\n",
    "  cur_sample = all_deals['num_users'].sample(20, replace=True)\n",
    "  # Take mean of cur_sample\n",
    "  cur_mean = np.mean(cur_sample)\n",
    "  # Append cur_mean to sample_means\n",
    "  sample_means.append(cur_mean)\n",
    "\n",
    "# Print mean of sample_means\n",
    "print(np.mean(sample_means))\n",
    "\n",
    "# Print mean of num_users in amir_deals\n",
    "print(np.mean(amir_deals['num_users']))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a293a33e",
   "metadata": {},
   "source": [
    "38.31333333333332\n",
    "37.651685393258425"
   ]
  },
  {
   "cell_type": "raw",
   "id": "493fbb88",
   "metadata": {},
   "source": [
    "# Step 1: Import poisson from scipy.stats\n",
    "from scipy.stats import poisson\n",
    "\n",
    "# Step 2: Define the average number of responses (mean lambda) Amir responds to per day\n",
    "avg_amir = 4\n",
    "\n",
    "# Step 3: Calculate the probability of Amir responding to exactly 5 leads in a day\n",
    "prob_5 = poisson.pmf(5, avg_amir)\n",
    "\n",
    "# Step 4: Print the calculated probability\n",
    "print(prob_5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d231d432",
   "metadata": {},
   "source": [
    "0.1562934518505317"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c93154c",
   "metadata": {},
   "source": [
    "# Step 1: Import poisson from scipy.stats\n",
    "from scipy.stats import poisson\n",
    "\n",
    "# Step 2: Define the average number of responses (mean lambda) Amir's coworker responds to per day\n",
    "avg_coworker = 5.5\n",
    "\n",
    "# Step 3: Calculate the probability of Amir's coworker responding to exactly 5 leads in a day\n",
    "prob_coworker = poisson.pmf(5, avg_coworker)\n",
    "\n",
    "# Step 4: Print the calculated probability\n",
    "print(prob_coworker)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e43a4ff8",
   "metadata": {},
   "source": [
    "0.17140068409793663"
   ]
  },
  {
   "cell_type": "raw",
   "id": "77d76f37",
   "metadata": {},
   "source": [
    "# Step 1: Import poisson from scipy.stats\n",
    "from scipy.stats import poisson\n",
    "\n",
    "# Step 2: Define the average number of responses (mean lambda) Amir responds to per day\n",
    "avg_amir = 4\n",
    "\n",
    "# Step 3: Calculate the probability that Amir responds to 2 or fewer leads in a day\n",
    "prob_2_or_less = poisson.cdf(2, avg_amir)\n",
    "\n",
    "# Step 4: Print the calculated probability\n",
    "print(prob_2_or_less)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "352542e6",
   "metadata": {},
   "source": [
    "# Step 1: Import poisson from scipy.stats\n",
    "from scipy.stats import poisson\n",
    "\n",
    "# Step 2: Define the average number of responses (mean lambda) Amir responds to per day\n",
    "avg_amir = 4\n",
    "\n",
    "# Step 3: Calculate the probability that Amir responds to more than 10 leads in a day\n",
    "prob_over_10 = 1 - poisson.cdf(10, avg_amir)\n",
    "\n",
    "# Step 4: Print the calculated probability\n",
    "print(prob_over_10)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b4dfe857",
   "metadata": {},
   "source": [
    "0.0028397661205137315"
   ]
  },
  {
   "cell_type": "raw",
   "id": "80b3b7da",
   "metadata": {},
   "source": [
    "# Import expon from scipy.stats\n",
    "from scipy.stats import expon\n",
    "\n",
    "# Calculate the probability that the response time is less than 1 hour\n",
    "probability = expon.cdf(1, scale=2.5)\n",
    "print(probability)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9efc776",
   "metadata": {},
   "source": [
    "0.3296799539643607"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6bd5e335",
   "metadata": {},
   "source": [
    "# Import expon from scipy.stats\n",
    "from scipy.stats import expon\n",
    "\n",
    "# Calculate the CDF for 4 hours with a scale parameter of 2.5\n",
    "cdf_value = expon.cdf(4, scale=2.5)\n",
    "\n",
    "# Print the probability that it takes more than 4 hours\n",
    "print(1 - cdf_value)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf45932c",
   "metadata": {},
   "source": [
    "0.20189651799465536"
   ]
  },
  {
   "cell_type": "raw",
   "id": "357028d5",
   "metadata": {},
   "source": [
    "# Import expon from scipy.stats\n",
    "from scipy.stats import expon\n",
    "\n",
    "# Calculate the CDF for 3 hours and 4 hours\n",
    "cdf_3_hours = expon.cdf(3, scale=2.5)\n",
    "cdf_4_hours = expon.cdf(4, scale=2.5)\n",
    "\n",
    "# Print the probability that the response time is between 3 and 4 hours\n",
    "print(cdf_4_hours - cdf_3_hours)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0006935",
   "metadata": {},
   "source": [
    "0.09929769391754684"
   ]
  },
  {
   "cell_type": "raw",
   "id": "04214f0a",
   "metadata": {},
   "source": [
    "# Create a scatterplot of happiness_score vs. life_exp and show\n",
    "sns.scatterplot(x='life_exp', y='happiness_score', data=world_happiness)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1499f36d",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create scatterplot of happiness_score vs life_exp with trendline\n",
    "sns.lmplot(x='life_exp', y='happiness_score', data=world_happiness, ci=None)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "857b1134",
   "metadata": {},
   "source": [
    "# Create scatterplot of happiness_score vs life_exp with trendline\n",
    "sns.lmplot(x='life_exp', y='happiness_score', data=world_happiness, ci=None)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Correlation between life_exp and happiness_score\n",
    "cor = world_happiness['life_exp'].corr(world_happiness['happiness_score'])\n",
    "\n",
    "print(cor)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20255791",
   "metadata": {},
   "source": [
    "0.7802249053272062"
   ]
  },
  {
   "cell_type": "raw",
   "id": "af66fc1b",
   "metadata": {},
   "source": [
    "# Scatterplot of gdp_per_cap and life_exp\n",
    "sns.scatterplot(x='gdp_per_cap', y='life_exp', data=world_happiness)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14c64013",
   "metadata": {},
   "source": [
    "# Scatterplot of gdp_per_cap and life_exp\n",
    "sns.scatterplot(x='gdp_per_cap', y='life_exp', data=world_happiness)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "  \n",
    "# Correlation between gdp_per_cap and life_exp\n",
    "cor = world_happiness['gdp_per_cap'].corr(world_happiness['life_exp'])\n",
    "\n",
    "print(cor)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9dad8fb2",
   "metadata": {},
   "source": [
    "0.7019547642148012"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c5ee50a",
   "metadata": {},
   "source": [
    "# Scatterplot of happiness_score vs. gdp_per_cap\n",
    "sns.scatterplot(x='gdp_per_cap', y='happiness_score', data=world_happiness)\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation\n",
    "cor = world_happiness['gdp_per_cap'].corr(world_happiness['happiness_score'])\n",
    "print(cor)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3dd428be",
   "metadata": {},
   "source": [
    "0.727973301222298"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0afd1e9",
   "metadata": {},
   "source": [
    "# Create log_gdp_per_cap column\n",
    "world_happiness['log_gdp_per_cap'] = np.log(world_happiness['gdp_per_cap'])\n",
    "\n",
    "# Scatterplot of happiness_score vs. log_gdp_per_cap\n",
    "sns.scatterplot(x='log_gdp_per_cap', y='happiness_score', data=world_happiness)\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation\n",
    "cor = world_happiness['log_gdp_per_cap'].corr(world_happiness['happiness_score'])\n",
    "print(cor)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2d4903f",
   "metadata": {},
   "source": [
    "0.8043146004918288"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2528cd4",
   "metadata": {},
   "source": [
    "# Scatterplot of grams_sugar_per_day and happiness_score\n",
    "sns.scatterplot(x='grams_sugar_per_day', y='happiness_score', data=world_happiness)\n",
    "plt.show()\n",
    "\n",
    "# Correlation between grams_sugar_per_day and happiness_score\n",
    "cor = world_happiness['grams_sugar_per_day'].corr(world_happiness['happiness_score'])\n",
    "print(cor)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "daffbc96",
   "metadata": {},
   "source": [
    "0.6939100021829633"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab87898a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

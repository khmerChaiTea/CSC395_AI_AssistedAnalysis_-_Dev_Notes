{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89573ef9",
   "metadata": {},
   "source": [
    "Inner Join"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce9a35e6",
   "metadata": {},
   "source": [
    "# Merge the taxi_owners and taxi_veh tables\n",
    "taxi_own_veh = taxi_owners.merge(taxi_veh, on='vid')\n",
    "\n",
    "# Print the column names of the taxi_own_veh\n",
    "print(taxi_own_veh.columns)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c49bcb6",
   "metadata": {},
   "source": [
    "Index(['rid', 'vid', 'owner_x', 'address', 'zip', 'make', 'model', 'year', 'fuel_type', 'owner_y'], dtype='object')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f9dae00",
   "metadata": {},
   "source": [
    "# Merge the taxi_owners and taxi_veh tables setting a suffix\n",
    "taxi_own_veh = taxi_owners.merge(taxi_veh, on='vid', suffixes=('_own', '_veh'))\n",
    "\n",
    "# Print the column names of taxi_own_veh\n",
    "print(taxi_own_veh.columns)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d7aaa37",
   "metadata": {},
   "source": [
    "Index(['rid', 'vid', 'owner_own', 'address', 'zip', 'make', 'model', 'year', 'fuel_type', 'owner_veh'], dtype='object')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "afffda17",
   "metadata": {},
   "source": [
    "# Merge the taxi_owners and taxi_veh tables setting a suffix\n",
    "taxi_own_veh = taxi_owners.merge(taxi_veh, on='vid', suffixes=('_own','_veh'))\n",
    "\n",
    "# Print the value_counts to find the most popular fuel_type\n",
    "print(taxi_own_veh['fuel_type'].value_counts())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "927a60b9",
   "metadata": {},
   "source": [
    "HYBRID                    2792\n",
    "GASOLINE                   611\n",
    "FLEX FUEL                   89\n",
    "COMPRESSED NATURAL GAS      27\n",
    "Name: fuel_type, dtype: int64"
   ]
  },
  {
   "cell_type": "raw",
   "id": "52659d20",
   "metadata": {},
   "source": [
    "# Merge the wards and census tables on the ward column\n",
    "wards_census = wards.merge(census, on='ward')\n",
    "\n",
    "# Print the shape of wards_census\n",
    "print('wards_census table shape:', wards_census.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b393983",
   "metadata": {},
   "source": [
    "wards_census table shape: (50, 9)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4617a91b",
   "metadata": {},
   "source": [
    "# Print the first few rows of the wards_altered table to view the change \n",
    "print(wards_altered[['ward']].head())\n",
    "\n",
    "# Merge the wards_altered and census tables on the ward column\n",
    "wards_altered_census = wards_altered.merge(census, on='ward')\n",
    "\n",
    "# Print the shape of wards_altered_census\n",
    "print('wards_altered_census table shape:', wards_altered_census.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47b034ea",
   "metadata": {},
   "source": [
    "  ward\n",
    "0   61\n",
    "1    2\n",
    "2    3\n",
    "3    4\n",
    "4    5\n",
    "wards_altered_census table shape: (49, 9)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ca219b3",
   "metadata": {},
   "source": [
    "# Print the first few rows of the census_altered table to view the change \n",
    "print(census_altered[['ward']].head())\n",
    "\n",
    "# Merge the wards and census_altered tables on the ward column\n",
    "wards_census_altered = wards.merge(census_altered, on='ward')\n",
    "\n",
    "# Print the shape of wards_census_altered\n",
    "print('wards_census_altered table shape:', wards_census_altered.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e86bb9c",
   "metadata": {},
   "source": [
    "   ward\n",
    "0  None\n",
    "1     2\n",
    "2     3\n",
    "3     4\n",
    "4     5\n",
    "wards_census_altered table shape: (49, 9)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "38765a34",
   "metadata": {},
   "source": [
    "# Merge the licenses and biz_owners table on account\n",
    "licenses_owners = pd.merge(licenses, biz_owners, on='account', how='left')\n",
    "\n",
    "# Group the results by title then count the number of accounts\n",
    "counted_df = licenses_owners.groupby('title').agg({'account':'count'})\n",
    "\n",
    "# Sort the counted_df in desending order\n",
    "sorted_df = counted_df.sort_values(by='account', ascending=False)\n",
    "\n",
    "# Use .head() method to print the first few rows of sorted_df\n",
    "print(sorted_df.head())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c94c6eb",
   "metadata": {},
   "source": [
    "                 account\n",
    "title                   \n",
    "PRESIDENT           6259\n",
    "SECRETARY           5205\n",
    "SOLE PROPRIETOR     1658\n",
    "OTHER               1200\n",
    "VICE PRESIDENT       970"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e79ea263",
   "metadata": {},
   "source": [
    "# Merge the ridership and cal tables\n",
    "ridership_cal = ridership.merge(cal, on=['year', 'month', 'day'], how=\"inner\")\n",
    "\n",
    "print(ridership_cal)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20e47629",
   "metadata": {},
   "source": [
    "     station_id  year  month  day  rides        day_type\n",
    "0         40010  2019      1    1    576  Sunday/Holiday\n",
    "1         40080  2019      1    1   1839  Sunday/Holiday\n",
    "2         40770  2019      1    1   2724  Sunday/Holiday\n",
    "3         40120  2019      1    1    754  Sunday/Holiday\n",
    "4         40540  2019      1    1   2175  Sunday/Holiday\n",
    "...         ...   ...    ...  ...    ...             ...\n",
    "3280      40540  2019     12   31   4355         Weekday\n",
    "3281      41260  2019     12   31   1228         Weekday\n",
    "3282      41500  2019     12   31   1685         Weekday\n",
    "3283      41440  2019     12   31   1370         Weekday\n",
    "3284      41660  2019     12   31  13430         Weekday\n",
    "\n",
    "[3285 rows x 6 columns]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4604f73",
   "metadata": {},
   "source": [
    "# Try merging the ridership and cal tables first, then merge the result with the stations table\n",
    "ridership_cal_stations = ridership.merge(cal, on=['year','month','day']) \\\n",
    "\t\t\t\t\t\t\t.merge(stations, on='station_id')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7fa1681a",
   "metadata": {},
   "source": [
    "# Merge the ridership, cal, and stations tables\n",
    "ridership_cal_stations = ridership.merge(cal, on=['year','month','day']) \\\n",
    "\t\t\t\t\t\t\t.merge(stations, on='station_id')\n",
    "\n",
    "# Example of creating a filter with multiple conditions\n",
    "filter_criteria = ((ridership_cal_stations['month'] == 7) \n",
    "                   & (ridership_cal_stations['day_type'] == 'Weekday') \n",
    "                   & (ridership_cal_stations['station_name'] == 'Wilson'))\n",
    "\n",
    "# Use .loc and the filter to select for rides\n",
    "print(ridership_cal_stations.loc[filter_criteria, 'rides'].sum())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f6f9475",
   "metadata": {},
   "source": [
    "# Merge licenses and zip_demo, on zip; and merge the wards on ward\n",
    "licenses_zip_ward = licenses.merge(zip_demo, on='zip') \\\n",
    "\t\t\t\t\t.merge(wards, on='ward')\n",
    "\n",
    "# Print the results by alderman and show median income\n",
    "print(licenses_zip_ward.groupby('alderman').agg({'income':'median'}))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "22840bd1",
   "metadata": {},
   "source": [
    "                             income\n",
    "alderman                           \n",
    "Ameya Pawar                 66246.0\n",
    "Anthony A. Beale            38206.0\n",
    "Anthony V. Napolitano       82226.0\n",
    "Ariel E. Reyboras           41307.0\n",
    "Brendan Reilly             110215.0\n",
    "Brian Hopkins               87143.0\n",
    "Carlos Ramirez-Rosa         66246.0\n",
    "Carrie M. Austin            38206.0\n",
    "Chris Taliaferro            55566.0\n",
    "Daniel \"Danny\" Solis        41226.0\n",
    "David H. Moore              33304.0\n",
    "Deborah Mell                66246.0\n",
    "Debra L. Silverstein        50554.0\n",
    "Derrick G. Curtis           65770.0\n",
    "Edward M. Burke             42335.0\n",
    "Emma M. Mitts               36283.0\n",
    "George Cardenas             33959.0\n",
    "Gilbert Villegas            41307.0\n",
    "Gregory I. Mitchell         24941.0\n",
    "Harry Osterman              45442.0\n",
    "Howard B. Brookins, Jr.     33304.0\n",
    "James Cappleman             79565.0\n",
    "Jason C. Ervin              41226.0\n",
    "Joe Moore                   39163.0\n",
    "John S. Arena               70122.0\n",
    "Leslie A. Hairston          28024.0\n",
    "Margaret Laurino            70122.0\n",
    "Marty Quinn                 67045.0\n",
    "Matthew J. O'Shea           59488.0\n",
    "Michael R. Zalewski         42335.0\n",
    "Michael Scott, Jr.          31445.0\n",
    "Michelle A. Harris          32558.0\n",
    "Michelle Smith             100116.0\n",
    "Milagros \"Milly\" Santiago   41307.0\n",
    "Nicholas Sposato            62223.0\n",
    "Pat Dowell                  46340.0\n",
    "Patrick Daley Thompson      41226.0\n",
    "Patrick J. O'Connor         50554.0\n",
    "Proco \"Joe\" Moreno          87143.0\n",
    "Raymond A. Lopez            33959.0\n",
    "Ricardo Munoz               31445.0\n",
    "Roberto Maldonado           68223.0\n",
    "Roderick T. Sawyer          32558.0\n",
    "Scott Waguespack            68223.0\n",
    "Susan Sadlowski Garza       38417.0\n",
    "Tom Tunney                  88708.0\n",
    "Toni L. Foulkes             27573.0\n",
    "Walter Burnett, Jr.         87143.0\n",
    "William D. Burns           107811.0\n",
    "Willie B. Cochran           28024.0"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eafd6530",
   "metadata": {},
   "source": [
    "# First, merge land_use and census on the 'ward' column\n",
    "merged_land_census = land_use.merge(census, on='ward')\n",
    "\n",
    "# Then, merge the result with licenses on the 'ward' column, using the suffixes\n",
    "land_cen_lic = merged_land_census.merge(licenses, on='ward', suffixes=('_cen', '_lic'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea8b84b3",
   "metadata": {},
   "source": [
    "# Merge land_use and census and merge result with licenses including suffixes\n",
    "land_cen_lic = land_use.merge(census, on='ward') \\\n",
    "                       .merge(licenses, on='ward', suffixes=('_cen', '_lic'))\n",
    "\n",
    "# Group by ward, pop_2010, and vacant, then count the # of accounts\n",
    "pop_vac_lic = land_cen_lic.groupby(['ward', 'pop_2010', 'vacant'], as_index=False) \\\n",
    "                           .agg({'account': 'count'})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f9b6e23",
   "metadata": {},
   "source": [
    "# Merge land_use and census and merge result with licenses including suffixes\n",
    "land_cen_lic = land_use.merge(census, on='ward') \\\n",
    "                    .merge(licenses, on='ward', suffixes=('_cen','_lic'))\n",
    "\n",
    "# Group by ward, pop_2010, and vacant, then count the # of accounts\n",
    "pop_vac_lic = land_cen_lic.groupby(['ward','pop_2010','vacant'], \n",
    "                                   as_index=False).agg({'account':'count'})\n",
    "\n",
    "# Sort pop_vac_lic by 'vacant' (descending), 'account' (ascending), and 'pop_2010' (ascending)\n",
    "sorted_pop_vac_lic = pop_vac_lic.sort_values(['vacant', 'account', 'pop_2010'], \n",
    "                                             ascending=[False, True, True])\n",
    "\n",
    "# Print the top few rows of sorted_pop_vac_lic\n",
    "print(sorted_pop_vac_lic.head())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "13d1d7a2",
   "metadata": {},
   "source": [
    "   ward  pop_2010  vacant  account\n",
    "47    7     51581      19       80\n",
    "12   20     52372      15      123\n",
    "1    10     51535      14      130\n",
    "16   24     54909      13       98\n",
    "7    16     51954      13      156"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fba4004",
   "metadata": {},
   "source": [
    "Left Join"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07e91981",
   "metadata": {},
   "source": [
    "# Merge movies and financials with a left join\n",
    "movies_financials = movies.merge(financials, on='id', how='left')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "333a8f2a",
   "metadata": {},
   "source": [
    "# Merge the movies table with the financials table with a left join\n",
    "movies_financials = movies.merge(financials, on='id', how='left')\n",
    "\n",
    "# Count the number of rows in the budget column that are missing\n",
    "number_of_missing_fin = movies_financials['budget'].isnull().sum()\n",
    "\n",
    "# Print the number of movies missing financials\n",
    "print(number_of_missing_fin)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8dc6a1a6",
   "metadata": {},
   "source": [
    "1574"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2dbfa05c",
   "metadata": {},
   "source": [
    "# Merge the toy_story and taglines tables with a left join\n",
    "toystory_tag = toy_story.merge(taglines, on='id', how='left')\n",
    "\n",
    "# Print the rows and shape of toystory_tag\n",
    "print(toystory_tag)\n",
    "print(toystory_tag.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "510d07c9",
   "metadata": {},
   "source": [
    "      id        title  popularity release_date                   tagline\n",
    "0  10193  Toy Story 3      59.995   2010-06-16  No toy gets left behind.\n",
    "1    863  Toy Story 2      73.575   1999-10-30        The toys are back!\n",
    "2    862    Toy Story      73.640   1995-10-30                       NaN\n",
    "(3, 5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "65d22ca4",
   "metadata": {},
   "source": [
    "# Merge the toy_story and taglines tables with a inner join\n",
    "toystory_tag = toy_story.merge(taglines, on='id', how='inner')\n",
    "\n",
    "# Print the rows and shape of toystory_tag\n",
    "print(toystory_tag)\n",
    "print(toystory_tag.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2aa4f732",
   "metadata": {},
   "source": [
    "      id        title  popularity release_date                   tagline\n",
    "0  10193  Toy Story 3      59.995   2010-06-16  No toy gets left behind.\n",
    "1    863  Toy Story 2      73.575   1999-10-30        The toys are back!\n",
    "(2, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a35fda",
   "metadata": {},
   "source": [
    "Right Join and Outer join"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2716675",
   "metadata": {},
   "source": [
    "# Merge action_movies to scifi_movies with right join\n",
    "action_scifi = action_movies.merge(scifi_movies, on='movie_id', how='right')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8235127c",
   "metadata": {},
   "source": [
    "# Merge action_movies to scifi_movies with right join\n",
    "action_scifi = action_movies.merge(scifi_movies, on='movie_id', how='right',\n",
    "                                   suffixes=('_act', '_sci'))\n",
    "\n",
    "# Print the first few rows of action_scifi to see the structure\n",
    "print(action_scifi.head())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "11a50ecb",
   "metadata": {},
   "source": [
    "   movie_id genre_act        genre_sci\n",
    "0        11    Action  Science Fiction\n",
    "1        18    Action  Science Fiction\n",
    "2        19       NaN  Science Fiction\n",
    "3        38       NaN  Science Fiction\n",
    "4        62       NaN  Science Fiction"
   ]
  },
  {
   "cell_type": "raw",
   "id": "025c17d1",
   "metadata": {},
   "source": [
    "# Merge action_movies to the scifi_movies with right join\n",
    "action_scifi = action_movies.merge(scifi_movies, on='movie_id', how='right',\n",
    "                                   suffixes=('_act','_sci'))\n",
    "\n",
    "# From action_scifi, select only the rows where the genre_act column is null\n",
    "scifi_only = action_scifi[action_scifi['genre_act'].isnull()]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c5d812c",
   "metadata": {},
   "source": [
    "# Merge action_movies to the scifi_movies with right join\n",
    "action_scifi = action_movies.merge(scifi_movies, on='movie_id', how='right',\n",
    "                                   suffixes=('_act','_sci'))\n",
    "\n",
    "# From action_scifi, select only the rows where the genre_act column is null\n",
    "scifi_only = action_scifi[action_scifi['genre_act'].isnull()]\n",
    "\n",
    "# Merge the movies and scifi_only tables with an inner join\n",
    "movies_and_scifi_only = movies.merge(scifi_only, left_on='id', right_on='movie_id', how='inner')\n",
    "\n",
    "# Print the first few rows and shape of movies_and_scifi_only\n",
    "print(movies_and_scifi_only.head())\n",
    "print(movies_and_scifi_only.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bafc4c8d",
   "metadata": {},
   "source": [
    "      id                         title  popularity release_date  movie_id genre_act        genre_sci\n",
    "0  18841  The Lost Skeleton of Cadavra       1.681   2001-09-12     18841       NaN  Science Fiction\n",
    "1  26672     The Thief and the Cobbler       2.439   1993-09-23     26672       NaN  Science Fiction\n",
    "2  15301      Twilight Zone: The Movie      12.903   1983-06-24     15301       NaN  Science Fiction\n",
    "3   8452                   The 6th Day      18.447   2000-11-17      8452       NaN  Science Fiction\n",
    "4   1649    Bill & Ted's Bogus Journey      11.350   1991-07-19      1649       NaN  Science Fiction\n",
    "(258, 7)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c583959",
   "metadata": {},
   "source": [
    "# Use right join to merge the movie_to_genres and pop_movies tables\n",
    "genres_movies = movie_to_genres.merge(pop_movies, left_on='movie_id', \n",
    "                                      right_on='id', \n",
    "                                      how='right')\n",
    "\n",
    "# Count the number of genres\n",
    "genre_count = genres_movies.groupby('genre').agg({'id':'count'})\n",
    "\n",
    "# Plot a bar chart of the genre_count\n",
    "genre_count.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2deb9b65",
   "metadata": {},
   "source": [
    "# Merge iron_1_actors to iron_2_actors on id with outer join using suffixes\n",
    "iron_1_and_2 = iron_1_actors.merge(iron_2_actors,  # Make sure to use 'iron_2_actors' here\n",
    "                                     on='id',\n",
    "                                     how='outer',\n",
    "                                     suffixes=('_1','_2'))\n",
    "\n",
    "# Create an index that returns true if name_1 or name_2 are null\n",
    "m = ((iron_1_and_2['name_1'].isnull()) | \n",
    "     (iron_1_and_2['name_2'].isnull()))  # Correct the method name to 'isnull'\n",
    "\n",
    "# Print the first few rows of iron_1_and_2\n",
    "print(iron_1_and_2[m].head())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "044390e9",
   "metadata": {},
   "source": [
    "                   character_1      id           name_1 character_2 name_2\n",
    "0                       Yinsen   17857       Shaun Toub         NaN    NaN\n",
    "2  Obadiah Stane / Iron Monger    1229     Jeff Bridges         NaN    NaN\n",
    "3                  War Machine   18288  Terrence Howard         NaN    NaN\n",
    "5                         Raza   57452      Faran Tahir         NaN    NaN\n",
    "8                   Abu Bakaar  173810    Sayed Badreya         NaN    NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fe2e34",
   "metadata": {},
   "source": [
    "Self Join - Merging same table (movie sequels)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4d0c3b12",
   "metadata": {},
   "source": [
    "# Merge the crews table to itself\n",
    "crews_self_merged = crews.merge(crews, on='id', suffixes=('_dir', \"_crew\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "97b85321",
   "metadata": {},
   "source": [
    "# Merge the crews table to itself\n",
    "crews_self_merged = crews.merge(crews, on='id', how='inner',\n",
    "                                suffixes=('_dir','_crew'))\n",
    "\n",
    "# Create a Boolean index to select the appropriate\n",
    "boolean_filter = ((crews_self_merged['job_dir'] == 'Director') & \n",
    "     (crews_self_merged['job_crew'] != 'Director'))\n",
    "direct_crews = crews_self_merged[boolean_filter]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "109b4b91",
   "metadata": {},
   "source": [
    "# Merge the crews table to itself\n",
    "crews_self_merged = crews.merge(crews, on='id', how='inner',\n",
    "                                suffixes=('_dir','_crew'))\n",
    "\n",
    "# Create a boolean index to select the appropriate rows\n",
    "boolean_filter = ((crews_self_merged['job_dir'] == 'Director') & \n",
    "                  (crews_self_merged['job_crew'] != 'Director'))\n",
    "direct_crews = crews_self_merged[boolean_filter]\n",
    "\n",
    "# Print the first few rows of direct_crews\n",
    "print(direct_crews.head())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a5caeff",
   "metadata": {},
   "source": [
    "        id   job_dir       name_dir        job_crew          name_crew\n",
    "156  19995  Director  James Cameron          Editor  Stephen E. Rivkin\n",
    "157  19995  Director  James Cameron  Sound Designer  Christopher Boyes\n",
    "158  19995  Director  James Cameron         Casting          Mali Finn\n",
    "160  19995  Director  James Cameron          Writer      James Cameron\n",
    "161  19995  Director  James Cameron    Set Designer    Richard F. Mays"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6f9ee75",
   "metadata": {},
   "source": [
    "# Merge to the movies table the ratings table on the index\n",
    "movies_ratings = movies.merge(ratings, left_index=True, right_index=True, how='left')\n",
    "\n",
    "# Print the first few rows of movies_ratings\n",
    "print(movies_ratings.head())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aa80770b",
   "metadata": {},
   "source": [
    "                      title  popularity release_date  vote_average  vote_count\n",
    "id                                                                            \n",
    "257            Oliver Twist      20.416   2005-09-23           6.7       274.0\n",
    "14290  Better Luck Tomorrow       3.877   2002-01-12           6.5        27.0\n",
    "38365             Grown Ups      38.864   2010-06-24           6.0      1705.0\n",
    "9672               Infamous       3.681   2006-11-16           6.4        60.0\n",
    "12819       Alpha and Omega      12.301   2010-09-17  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "820e54fb",
   "metadata": {},
   "source": [
    "# Merge sequels and financials on index id\n",
    "sequels_fin = sequels.merge(financials, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e6c433a",
   "metadata": {},
   "source": [
    "# Merge sequels and financials on index id\n",
    "sequels_fin = sequels.merge(financials, on='id', how='left')\n",
    "\n",
    "# Self merge with suffixes as inner join with left on sequel and right on id\n",
    "orig_seq = sequels_fin.merge(sequels_fin, how='inner', left_on='sequel', \n",
    "                             right_on='id', right_index=True,\n",
    "                             suffixes=('_org','_seq'))\n",
    "\n",
    "# Add calculation to subtract revenue_org from revenue_seq \n",
    "orig_seq['diff'] = orig_seq['revenue_seq'] - orig_seq['revenue_org']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "073512ab",
   "metadata": {},
   "source": [
    "# Merge sequels and financials on index id\n",
    "sequels_fin = sequels.merge(financials, on='id', how='left')\n",
    "\n",
    "# Self merge with suffixes as inner join with left on sequel and right on id\n",
    "orig_seq = sequels_fin.merge(sequels_fin, how='inner', left_on='sequel', \n",
    "                             right_on='id', right_index=True,\n",
    "                             suffixes=('_org','_seq'))\n",
    "\n",
    "# Add calculation to subtract revenue_org from revenue_seq \n",
    "orig_seq['diff'] = orig_seq['revenue_seq'] - orig_seq['revenue_org']\n",
    "\n",
    "# Select the title_org, title_seq, and diff \n",
    "titles_diff = orig_seq[['title_org', 'title_seq', 'diff']]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "775545f5",
   "metadata": {},
   "source": [
    "# Merge sequels and financials on index id\n",
    "sequels_fin = sequels.merge(financials, on='id', how='left')\n",
    "\n",
    "# Self merge with suffixes as inner join with left on sequel and right on id\n",
    "orig_seq = sequels_fin.merge(sequels_fin, how='inner', left_on='sequel', \n",
    "                             right_on='id', right_index=True,\n",
    "                             suffixes=('_org','_seq'))\n",
    "\n",
    "# Add calculation to subtract revenue_org from revenue_seq \n",
    "orig_seq['diff'] = orig_seq['revenue_seq'] - orig_seq['revenue_org']\n",
    "\n",
    "# Select the title_org, title_seq, and diff \n",
    "titles_diff = orig_seq[['title_org','title_seq','diff']]\n",
    "\n",
    "# Print the first rows of the sorted titles_diff\n",
    "print(titles_diff.sort_values('diff', ascending=False).head())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98a6d8c7",
   "metadata": {},
   "source": [
    "               title_org        title_seq       diff\n",
    "id                                                  \n",
    "331    Jurassic Park III   Jurassic World  1.145e+09\n",
    "272        Batman Begins  The Dark Knight  6.303e+08\n",
    "10138         Iron Man 2       Iron Man 3  5.915e+08\n",
    "863          Toy Story 2      Toy Story 3  5.696e+08\n",
    "10764  Quantum of Solace          Skyfall  5.225e+08"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f54908d5",
   "metadata": {},
   "source": [
    "empl_cust = employees.merge(top_cust, on='srid', \n",
    "                            how='left', indicator=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "088b5723",
   "metadata": {},
   "source": [
    "# Merge employees and top_cust\n",
    "empl_cust = employees.merge(top_cust, on='srid', \n",
    "                            how='left', indicator=True)\n",
    "\n",
    "# Select the srid column where _merge is left_only\n",
    "srid_list = empl_cust.loc[empl_cust['_merge'] == 'left_only', 'srid']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a792d27",
   "metadata": {},
   "source": [
    "# Merge employees and top_cust\n",
    "empl_cust = employees.merge(top_cust, on='srid', \n",
    "                                 how='left', indicator=True)\n",
    "\n",
    "# Select the srid column where _merge is left_only\n",
    "srid_list = empl_cust.loc[empl_cust['_merge'] == 'left_only', 'srid']\n",
    "\n",
    "# Get employees not working with top customers\n",
    "print(employees[employees['srid'].isin(srid_list)])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2039b889",
   "metadata": {},
   "source": [
    "   srid     lname    fname            title  hire_date                    email\n",
    "0     1     Adams   Andrew  General Manager 2002-08-14   andrew@chinookcorp.com\n",
    "1     2   Edwards    Nancy    Sales Manager 2002-05-01    nancy@chinookcorp.com\n",
    "5     6  Mitchell  Michael       IT Manager 2003-10-17  michael@chinookcorp.com\n",
    "6     7      King   Robert         IT Staff 2004-01-02   robert@chinookcorp.com\n",
    "7     8  Callahan    Laura         IT Staff 2004-03-04    laura@chinookcorp.com"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c0efbb3",
   "metadata": {},
   "source": [
    "# Merge the non_mus_tck and top_invoices tables on tid\n",
    "tracks_invoices = non_mus_tcks.merge(top_invoices, on='tid', how='inner')\n",
    "\n",
    "# Use .isin() to subset non_mus_tcks to rows with tid in tracks_invoices\n",
    "top_tracks = non_mus_tcks[non_mus_tcks['tid'].isin(tracks_invoices['tid'])]\n",
    "\n",
    "# Group the top_tracks by gid and count the tid rows\n",
    "cnt_by_gid = top_tracks.groupby(['gid'], as_index=False).agg({'tid': 'count'})\n",
    "\n",
    "# Merge the genres table to cnt_by_gid on gid and print\n",
    "print(pd.merge(cnt_by_gid, genres, on='gid'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42dc3daf",
   "metadata": {},
   "source": [
    "   gid  tid      name\n",
    "0   19    4  TV Shows\n",
    "1   21    2     Drama\n",
    "2   22    1    Comedy"
   ]
  },
  {
   "cell_type": "raw",
   "id": "962adef5",
   "metadata": {},
   "source": [
    "# Concatenate the tracks\n",
    "tracks_from_albums = pd.concat([tracks_master, tracks_ride, tracks_st],\n",
    "                               sort=True)\n",
    "print(tracks_from_albums)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9e6fc3c",
   "metadata": {},
   "source": [
    "   aid             composer  gid  mtid                     name   tid  u_price\n",
    "0  152  J.Hetfield/L.Ulrich    3     1                  Battery  1853     0.99\n",
    "1  152            K.Hammett    3     1        Master Of Puppets  1854     0.99\n",
    "4  152  J.Hetfield/L.Ulrich    3     1        Disposable Heroes  1857     0.99\n",
    "0  154                  NaN    3     1     Fight Fire With Fire  1874     0.99\n",
    "1  154                  NaN    3     1       Ride The Lightning  1875     0.99\n",
    "2  154                  NaN    3     1  For Whom The Bell Tolls  1876     0.99\n",
    "3  154                  NaN    3     1            Fade To Black  1877     0.99\n",
    "4  154                  NaN    3     1        Trapped Under Ice  1878     0.99\n",
    "0  155                  NaN    3     1                  Frantic  1882     0.99\n",
    "1  155                  NaN    3     1                St. Anger  1883     0.99\n",
    "2  155                  NaN    3     1     Some Kind Of Monster  1884     0.99\n",
    "3  155                  NaN    3     1             Dirty Window  1885     0.99\n",
    "4  155                  NaN    3     1            Invisible Kid  1886     0.99"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2cbdf02a",
   "metadata": {},
   "source": [
    "# Concatenate the tracks so the index goes from 0 to n-1\n",
    "tracks_from_albums = pd.concat([tracks_master, tracks_ride, tracks_st], ignore_index=True,\n",
    "                               sort=True)\n",
    "print(tracks_from_albums)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b4b0c274",
   "metadata": {},
   "source": [
    "    aid             composer  gid  mtid                     name   tid  u_price\n",
    "0   152  J.Hetfield/L.Ulrich    3     1                  Battery  1853     0.99\n",
    "1   152            K.Hammett    3     1        Master Of Puppets  1854     0.99\n",
    "2   152  J.Hetfield/L.Ulrich    3     1        Disposable Heroes  1857     0.99\n",
    "3   154                  NaN    3     1     Fight Fire With Fire  1874     0.99\n",
    "4   154                  NaN    3     1       Ride The Lightning  1875     0.99\n",
    "5   154                  NaN    3     1  For Whom The Bell Tolls  1876     0.99\n",
    "6   154                  NaN    3     1            Fade To Black  1877     0.99\n",
    "7   154                  NaN    3     1        Trapped Under Ice  1878     0.99\n",
    "8   155                  NaN    3     1                  Frantic  1882     0.99\n",
    "9   155                  NaN    3     1                St. Anger  1883     0.99\n",
    "10  155                  NaN    3     1     Some Kind Of Monster  1884     0.99\n",
    "11  155                  NaN    3     1             Dirty Window  1885     0.99\n",
    "12  155                  NaN    3     1            Invisible Kid  1886     0.99"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5a253b0",
   "metadata": {},
   "source": [
    "# Concatenate the tracks, show only columns names that are in all tables\n",
    "tracks_from_albums = pd.concat([tracks_master, tracks_ride, tracks_st],\n",
    "                               join='inner',\n",
    "                               sort=True)\n",
    "print(tracks_from_albums)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "97d10de4",
   "metadata": {},
   "source": [
    "   aid  gid  mtid                     name   tid  u_price\n",
    "0  152    3     1                  Battery  1853     0.99\n",
    "1  152    3     1        Master Of Puppets  1854     0.99\n",
    "4  152    3     1        Disposable Heroes  1857     0.99\n",
    "0  154    3     1     Fight Fire With Fire  1874     0.99\n",
    "1  154    3     1       Ride The Lightning  1875     0.99\n",
    "2  154    3     1  For Whom The Bell Tolls  1876     0.99\n",
    "3  154    3     1            Fade To Black  1877     0.99\n",
    "4  154    3     1        Trapped Under Ice  1878     0.99\n",
    "0  155    3     1                  Frantic  1882     0.99\n",
    "1  155    3     1                St. Anger  1883     0.99\n",
    "2  155    3     1     Some Kind Of Monster  1884     0.99\n",
    "3  155    3     1             Dirty Window  1885     0.99\n",
    "4  155    3     1            Invisible Kid  1886     0.99"
   ]
  },
  {
   "cell_type": "raw",
   "id": "afd82aed",
   "metadata": {},
   "source": [
    "# Concatenate the tables and add keys\n",
    "inv_jul_thr_sep = pd.concat([inv_jul, inv_aug, inv_sep], \n",
    "                            keys=['7Jul', '8Aug', '9Sep'])\n",
    "\n",
    "# Group the invoices by the index keys and find avg of the total column\n",
    "avg_inv_by_month = inv_jul_thr_sep.groupby(level=0).agg({'total': 'mean'})\n",
    "\n",
    "# Bar plot of avg_inv_by_month\n",
    "avg_inv_by_month.plot(kind='bar', xlabel='Month', ylabel='Average Invoice Total', title='Average Invoice Total by Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5076a46",
   "metadata": {},
   "source": [
    "# Concatenate the classic tables vertically\n",
    "classic_18_19 = pd.concat([classic_18, classic_19], ignore_index=True)\n",
    "\n",
    "# Concatenate the pop tables vertically\n",
    "pop_18_19 = pd.concat([pop_18, pop_19], ignore_index=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "087d0072",
   "metadata": {},
   "source": [
    "# Concatenate the classic tables vertically\n",
    "classic_18_19 = pd.concat([classic_18, classic_19], ignore_index=True)\n",
    "\n",
    "# Concatenate the pop tables vertically\n",
    "pop_18_19 = pd.concat([pop_18, pop_19], ignore_index=True)\n",
    "\n",
    "# Merge classic_18_19 with pop_18_19\n",
    "classic_pop = classic_18_19.merge(pop_18_19, on='tid')\n",
    "\n",
    "# Using .isin(), filter classic_18_19 rows where tid is in classic_pop\n",
    "popular_classic = classic_18_19[classic_18_19['tid'].isin(classic_pop['tid'])]\n",
    "\n",
    "# Print popular chart\n",
    "print(popular_classic)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53bcbc70",
   "metadata": {},
   "source": [
    "    pid   tid\n",
    "3    12  3479\n",
    "10   12  3439\n",
    "21   12  3445\n",
    "23   12  3449\n",
    "48   12  3437\n",
    "50   12  3435"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd25b3f4",
   "metadata": {},
   "source": [
    "# Use merge_ordered() to merge gdp and sp500 on year and date\n",
    "gdp_sp500 = pd.merge_ordered(gdp, sp500, left_on='year', right_on='date', how='left')\n",
    "\n",
    "# Print gdp_sp500\n",
    "print(gdp_sp500)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37c19abb",
   "metadata": {},
   "source": [
    "  country code  year        gdp    date  returns\n",
    "0          USA  2010  1.499e+13  2010.0    12.78\n",
    "1          USA  2011  1.554e+13  2011.0     0.00\n",
    "2          USA  2012  1.620e+13  2012.0    13.41\n",
    "3          USA  2012  1.620e+13  2012.0    13.41\n",
    "4          USA  2013  1.678e+13  2013.0    29.60\n",
    "5          USA  2014  1.752e+13  2014.0    11.39\n",
    "6          USA  2015  1.822e+13  2015.0    -0.73\n",
    "7          USA  2016  1.871e+13  2016.0     9.54\n",
    "8          USA  2017  1.949e+13  2017.0    19.42\n",
    "9          USA  2018  2.049e+13     NaN      NaN"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5a2fe0f",
   "metadata": {},
   "source": [
    "# Use merge_ordered() to merge gdp and sp500, interpolate missing value\n",
    "gdp_sp500 = pd.merge_ordered(gdp, sp500, left_on='year', right_on='date', \n",
    "                             how='left', fill_method='ffill')\n",
    "\n",
    "# Print gdp_sp500\n",
    "print(gdp_sp500)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "752cb7b6",
   "metadata": {},
   "source": [
    "  country code  year        gdp  date  returns\n",
    "0          USA  2010  1.499e+13  2010    12.78\n",
    "1          USA  2011  1.554e+13  2011     0.00\n",
    "2          USA  2012  1.620e+13  2012    13.41\n",
    "3          USA  2012  1.620e+13  2012    13.41\n",
    "4          USA  2013  1.678e+13  2013    29.60\n",
    "5          USA  2014  1.752e+13  2014    11.39\n",
    "6          USA  2015  1.822e+13  2015    -0.73\n",
    "7          USA  2016  1.871e+13  2016     9.54\n",
    "8          USA  2017  1.949e+13  2017    19.42\n",
    "9          USA  2018  2.049e+13  2017    19.42"
   ]
  },
  {
   "cell_type": "raw",
   "id": "365e43cb",
   "metadata": {},
   "source": [
    "# Use merge_ordered() to merge gdp and sp500, interpolate missing value\n",
    "gdp_sp500 = pd.merge_ordered(gdp, sp500, left_on='year', right_on='date', \n",
    "                             how='left',  fill_method='ffill')\n",
    "\n",
    "# Subset the gdp and returns columns\n",
    "gdp_returns = gdp_sp500[['gdp', 'returns']]\n",
    "\n",
    "# Print gdp_returns correlation\n",
    "print(gdp_returns.corr())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3557182a",
   "metadata": {},
   "source": [
    "           gdp  returns\n",
    "gdp      1.000    0.212\n",
    "returns  0.212    1.000"
   ]
  },
  {
   "cell_type": "raw",
   "id": "03c56edf",
   "metadata": {},
   "source": [
    "# Use merge_ordered() to merge inflation, unemployment with inner join\n",
    "inflation_unemploy = pd.merge_ordered(inflation, unemployment, on='date', how='inner')\n",
    "\n",
    "\n",
    "# Print inflation_unemploy \n",
    "print(inflation_unemploy)\n",
    "\n",
    "# Plot a scatter plot of unemployment_rate vs cpi of inflation_unemploy\n",
    "inflation_unemploy.plot(kind='scatter', x='unemployment_rate', y='cpi', alpha=0.5)\n",
    "plt.title('Phillips Curve: Unemployment Rate vs. CPI')\n",
    "plt.xlabel('Unemployment Rate (%)')\n",
    "plt.ylabel('CPI (Inflation)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57ff28e1",
   "metadata": {},
   "source": [
    "         date      cpi     seriesid                  data_type  unemployment_rate\n",
    "0  2014-01-01  235.288  CUSR0000SA0  SEASONALLY ADJUSTED INDEX                6.7\n",
    "1  2014-06-01  237.231  CUSR0000SA0  SEASONALLY ADJUSTED INDEX                6.1\n",
    "2  2015-01-01  234.718  CUSR0000SA0  SEASONALLY ADJUSTED INDEX                5.6\n",
    "3  2015-06-01  237.684  CUSR0000SA0  SEASONALLY ADJUSTED INDEX                5.3\n",
    "4  2016-01-01  237.833  CUSR0000SA0  SEASONALLY ADJUSTED INDEX                5.0\n",
    "5  2016-06-01  240.167  CUSR0000SA0  SEASONALLY ADJUSTED INDEX                4.9\n",
    "6  2017-01-01  243.780  CUSR0000SA0  SEASONALLY ADJUSTED INDEX                4.7\n",
    "7  2017-06-01  244.182  CUSR0000SA0  SEASONALLY ADJUSTED INDEX                4.3\n",
    "8  2018-01-01  248.884  CUSR0000SA0  SEASONALLY ADJUSTED INDEX                4.1\n",
    "9  2018-06-01  251.134  CUSR0000SA0  SEASONALLY ADJUSTED INDEX                4.0"
   ]
  },
  {
   "cell_type": "raw",
   "id": "03c886ac",
   "metadata": {},
   "source": [
    "# Merge gdp and pop on date and country with fill and notice rows 2 and 3\n",
    "ctry_date = pd.merge_ordered(gdp, pop, on=['date', 'country'], \n",
    "                             fill_method='ffill')\n",
    "\n",
    "# Print ctry_date\n",
    "print(ctry_date)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ac09d9c",
   "metadata": {},
   "source": [
    "         date    country         gdp  series_code_x       pop series_code_y\n",
    "0  1990-01-01  Australia  158051.132  NYGDPMKTPSAKD  17065100   SP.POP.TOTL\n",
    "1  1990-01-01     Sweden   79837.846  NYGDPMKTPSAKD   8558835   SP.POP.TOTL\n",
    "2  1990-04-01  Australia  158263.582  NYGDPMKTPSAKD   8558835   SP.POP.TOTL\n",
    "3  1990-04-01     Sweden   80582.286  NYGDPMKTPSAKD   8558835   SP.POP.TOTL\n",
    "4  1990-07-01  Australia  157329.279  NYGDPMKTPSAKD   8558835   SP.POP.TOTL\n",
    "5  1990-07-01     Sweden   79974.360  NYGDPMKTPSAKD   8558835   SP.POP.TOTL\n",
    "6  1990-09-01  Australia  158240.678  NYGDPMKTPSAKD   8558835   SP.POP.TOTL\n",
    "7  1990-09-01     Sweden   80106.497  NYGDPMKTPSAKD   8558835   SP.POP.TOTL\n",
    "8  1991-01-01  Australia  156195.954  NYGDPMKTPSAKD  17284000   SP.POP.TOTL\n",
    "9  1991-01-01     Sweden   79524.242  NYGDPMKTPSAKD   8617375   SP.POP.TOTL\n",
    "10 1991-04-01  Australia  155989.033  NYGDPMKTPSAKD   8617375   SP.POP.TOTL\n",
    "11 1991-04-01     Sweden   79073.059  NYGDPMKTPSAKD   8617375   SP.POP.TOTL\n",
    "12 1991-07-01  Australia  156635.858  NYGDPMKTPSAKD   8617375   SP.POP.TOTL\n",
    "13 1991-07-01     Sweden   79084.770  NYGDPMKTPSAKD   8617375   SP.POP.TOTL\n",
    "14 1991-09-01  Australia  156744.057  NYGDPMKTPSAKD   8617375   SP.POP.TOTL\n",
    "15 1991-09-01     Sweden   79740.606  NYGDPMKTPSAKD   8617375   SP.POP.TOTL\n",
    "16 1992-01-01  Australia  157916.081  NYGDPMKTPSAKD  17495000   SP.POP.TOTL\n",
    "17 1992-01-01     Sweden   79390.922  NYGDPMKTPSAKD   8668067   SP.POP.TOTL\n",
    "18 1992-04-01  Australia  159047.827  NYGDPMKTPSAKD   8668067   SP.POP.TOTL\n",
    "19 1992-04-01     Sweden   79060.283  NYGDPMKTPSAKD   8668067   SP.POP.TOTL\n",
    "20 1992-07-01  Australia  160658.176  NYGDPMKTPSAKD   8668067   SP.POP.TOTL\n",
    "21 1992-07-01     Sweden   78904.605  NYGDPMKTPSAKD   8668067   SP.POP.TOTL\n",
    "22 1992-09-01  Australia  163960.221  NYGDPMKTPSAKD   8668067   SP.POP.TOTL\n",
    "23 1992-09-01     Sweden   76996.837  NYGDPMKTPSAKD   8668067   SP.POP.TOTL\n",
    "24 1993-01-01  Australia  165097.495  NYGDPMKTPSAKD  17667000   SP.POP.TOTL\n",
    "25 1993-01-01     Sweden   75783.588  NYGDPMKTPSAKD   8718561   SP.POP.TOTL\n",
    "26 1993-04-01  Australia  166027.059  NYGDPMKTPSAKD   8718561   SP.POP.TOTL\n",
    "27 1993-04-01     Sweden   76708.548  NYGDPMKTPSAKD   8718561   SP.POP.TOTL\n",
    "28 1993-07-01  Australia  166203.179  NYGDPMKTPSAKD   8718561   SP.POP.TOTL\n",
    "29 1993-07-01     Sweden   77662.018  NYGDPMKTPSAKD   8718561   SP.POP.TOTL\n",
    "30 1993-09-01  Australia  169279.348  NYGDPMKTPSAKD   8718561   SP.POP.TOTL\n",
    "31 1993-09-01     Sweden   77703.304  NYGDPMKTPSAKD   8718561   SP.POP.TOTL"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c3a1d38",
   "metadata": {},
   "source": [
    "# Merge gdp and pop on country and date with fill\n",
    "date_ctry = pd.merge_ordered(gdp, pop, on=['country', 'date'], fill_method='ffill')\n",
    "\n",
    "# Print date_ctry\n",
    "print(date_ctry)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c3ac7c9a",
   "metadata": {},
   "source": [
    "         date    country         gdp  series_code_x       pop series_code_y\n",
    "0  1990-01-01  Australia  158051.132  NYGDPMKTPSAKD  17065100   SP.POP.TOTL\n",
    "1  1990-04-01  Australia  158263.582  NYGDPMKTPSAKD  17065100   SP.POP.TOTL\n",
    "2  1990-07-01  Australia  157329.279  NYGDPMKTPSAKD  17065100   SP.POP.TOTL\n",
    "3  1990-09-01  Australia  158240.678  NYGDPMKTPSAKD  17065100   SP.POP.TOTL\n",
    "4  1991-01-01  Australia  156195.954  NYGDPMKTPSAKD  17284000   SP.POP.TOTL\n",
    "5  1991-04-01  Australia  155989.033  NYGDPMKTPSAKD  17284000   SP.POP.TOTL\n",
    "6  1991-07-01  Australia  156635.858  NYGDPMKTPSAKD  17284000   SP.POP.TOTL\n",
    "7  1991-09-01  Australia  156744.057  NYGDPMKTPSAKD  17284000   SP.POP.TOTL\n",
    "8  1992-01-01  Australia  157916.081  NYGDPMKTPSAKD  17495000   SP.POP.TOTL\n",
    "9  1992-04-01  Australia  159047.827  NYGDPMKTPSAKD  17495000   SP.POP.TOTL\n",
    "10 1992-07-01  Australia  160658.176  NYGDPMKTPSAKD  17495000   SP.POP.TOTL\n",
    "11 1992-09-01  Australia  163960.221  NYGDPMKTPSAKD  17495000   SP.POP.TOTL\n",
    "12 1993-01-01  Australia  165097.495  NYGDPMKTPSAKD  17667000   SP.POP.TOTL\n",
    "13 1993-04-01  Australia  166027.059  NYGDPMKTPSAKD  17667000   SP.POP.TOTL\n",
    "14 1993-07-01  Australia  166203.179  NYGDPMKTPSAKD  17667000   SP.POP.TOTL\n",
    "15 1993-09-01  Australia  169279.348  NYGDPMKTPSAKD  17667000   SP.POP.TOTL\n",
    "16 1990-01-01     Sweden   79837.846  NYGDPMKTPSAKD   8558835   SP.POP.TOTL\n",
    "17 1990-04-01     Sweden   80582.286  NYGDPMKTPSAKD   8558835   SP.POP.TOTL\n",
    "18 1990-07-01     Sweden   79974.360  NYGDPMKTPSAKD   8558835   SP.POP.TOTL\n",
    "19 1990-09-01     Sweden   80106.497  NYGDPMKTPSAKD   8558835   SP.POP.TOTL\n",
    "20 1991-01-01     Sweden   79524.242  NYGDPMKTPSAKD   8617375   SP.POP.TOTL\n",
    "21 1991-04-01     Sweden   79073.059  NYGDPMKTPSAKD   8617375   SP.POP.TOTL\n",
    "22 1991-07-01     Sweden   79084.770  NYGDPMKTPSAKD   8617375   SP.POP.TOTL\n",
    "23 1991-09-01     Sweden   79740.606  NYGDPMKTPSAKD   8617375   SP.POP.TOTL\n",
    "24 1992-01-01     Sweden   79390.922  NYGDPMKTPSAKD   8668067   SP.POP.TOTL\n",
    "25 1992-04-01     Sweden   79060.283  NYGDPMKTPSAKD   8668067   SP.POP.TOTL\n",
    "26 1992-07-01     Sweden   78904.605  NYGDPMKTPSAKD   8668067   SP.POP.TOTL\n",
    "27 1992-09-01     Sweden   76996.837  NYGDPMKTPSAKD   8668067   SP.POP.TOTL\n",
    "28 1993-01-01     Sweden   75783.588  NYGDPMKTPSAKD   8718561   SP.POP.TOTL\n",
    "29 1993-04-01     Sweden   76708.548  NYGDPMKTPSAKD   8718561   SP.POP.TOTL\n",
    "30 1993-07-01     Sweden   77662.018  NYGDPMKTPSAKD   8718561   SP.POP.TOTL\n",
    "31 1993-09-01     Sweden   77703.304  NYGDPMKTPSAKD   8718561   SP.POP.TOTL"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8db6d212",
   "metadata": {},
   "source": [
    "# Use merge_asof() to merge jpm and wells\n",
    "jpm_wells = pd.merge_asof(jpm, wells, on='date_time', suffixes=('', '_wells'), direction='nearest')\n",
    "\n",
    "# Use merge_asof() to merge jpm_wells and bac\n",
    "jpm_wells_bac = pd.merge_asof(jpm_wells, bac, on='date_time', suffixes=('_jpm', '_bac'), direction='nearest')\n",
    "\n",
    "# Compute price diff\n",
    "price_diffs = jpm_wells_bac.diff()\n",
    "\n",
    "# Plot the price diff of the close of jpm, wells and bac only\n",
    "price_diffs.plot(y=['close_jpm', 'close_wells', 'close_bac'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b957fb2",
   "metadata": {},
   "source": [
    "# Merge gdp and recession on date using merge_asof()\n",
    "gdp_recession = pd.merge_asof(gdp, recession, on='date')\n",
    "\n",
    "# Create a list based on the row value of gdp_recession['econ_status']\n",
    "is_recession = ['r' if s == 'recession' else 'g' for s in gdp_recession['econ_status']]\n",
    "\n",
    "# Plot a bar chart of gdp_recession\n",
    "gdp_recession.plot(kind='bar', y='gdp', x='date', color=is_recession, rot=90)\n",
    "plt.title('Quarterly GDP with Recession Status')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('GDP')\n",
    "plt.legend(handles=[plt.Rectangle((0,0),1,1, color='r'), plt.Rectangle((0,0),1,1, color='g')], labels=['Recession', 'Non-Recession'], loc='best')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4427ab42",
   "metadata": {},
   "source": [
    "# Merge gdp and pop on date and country with fill\n",
    "gdp_pop = pd.merge_ordered(gdp, pop, on=['country', 'date'], fill_method='ffill')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c73d095",
   "metadata": {},
   "source": [
    "# Merge gdp and pop on date and country with fill\n",
    "gdp_pop = pd.merge_ordered(gdp, pop, on=['country','date'], fill_method='ffill')\n",
    "\n",
    "# Add a column named gdp_per_capita to gdp_pop that divides the gdp by pop\n",
    "gdp_pop['gdp_per_capita'] = gdp_pop['gdp'] / gdp_pop['pop']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75855a0e",
   "metadata": {},
   "source": [
    "# Merge gdp and pop on date and country with fill\n",
    "gdp_pop = pd.merge_ordered(gdp, pop, on=['country','date'], fill_method='ffill')\n",
    "\n",
    "# Add a column named gdp_per_capita to gdp_pop that divides the gdp by pop\n",
    "gdp_pop['gdp_per_capita'] = gdp_pop['gdp'] / gdp_pop['pop']\n",
    "\n",
    "# Pivot table of gdp_per_capita, where index is date and columns is country\n",
    "gdp_pivot = gdp_pop.pivot_table('gdp_per_capita', 'date', 'country')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2393a993",
   "metadata": {},
   "source": [
    "# Merge gdp and pop on date and country with fill\n",
    "gdp_pop = pd.merge_ordered(gdp, pop, on=['country','date'], fill_method='ffill')\n",
    "\n",
    "# Add a column named gdp_per_capita to gdp_pop that divides the gdp by pop\n",
    "gdp_pop['gdp_per_capita'] = gdp_pop['gdp'] / gdp_pop['pop']\n",
    "\n",
    "# Pivot data so gdp_per_capita, where index is date and columns is country\n",
    "gdp_pivot = gdp_pop.pivot_table('gdp_per_capita', 'date', 'country')\n",
    "\n",
    "# Select dates equal to or greater than 1991-01-01\n",
    "recent_gdp_pop = gdp_pivot.query('date >= \"1991-01-01\"')\n",
    "\n",
    "# Plot recent_gdp_pop\n",
    "recent_gdp_pop.plot(rot=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "24079616",
   "metadata": {},
   "source": [
    "# unpivot everything besides the year column\n",
    "ur_tall = ur_wide.melt(id_vars=['year'], var_name='month', value_name='unempl_rate')\n",
    "\n",
    "# Create a date column using the month and year columns of ur_tall\n",
    "ur_tall['date'] = pd.to_datetime(ur_tall['year'].astype(str) + '-' + ur_tall['month'], format='%Y-%b')\n",
    "\n",
    "# Sort ur_tall by date in ascending order\n",
    "ur_sorted = ur_tall.sort_values(by='date')\n",
    "\n",
    "# Plot the unempl_rate by date\n",
    "ur_sorted.plot(x='date', y='unempl_rate')\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(ur_sorted['date'], ur_sorted['unempl_rate'], marker='o', linestyle='-', color='b')\n",
    "plt.title('US Unemployment Rate Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Unemployment Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f202f2e",
   "metadata": {},
   "source": [
    "# Use melt on ten_yr, unpivot everything besides the metric column\n",
    "bond_perc = ten_yr.melt(id_vars='metric', var_name='date', value_name='close')\n",
    "\n",
    "# Use query on bond_perc to select only the rows where metric=close\n",
    "bond_perc_close = bond_perc.query('metric == \"close\"')\n",
    "\n",
    "# Merge (ordered) dji and bond_perc_close on date with an inner join\n",
    "dow_bond = pd.merge_ordered(dji, bond_perc_close, on='date', suffixes=('_dow', '_bond'), how='inner')\n",
    "\n",
    "# Plot only the close_dow and close_bond columns\n",
    "dow_bond.plot(y=['close_dow', 'close_bond'], x='date', rot=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bcd149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

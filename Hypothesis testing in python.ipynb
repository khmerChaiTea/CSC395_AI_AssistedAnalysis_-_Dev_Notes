{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3b6c5237",
   "metadata": {},
   "source": [
    "# Print the late_shipments dataset\n",
    "print(late_shipments)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3943f432",
   "metadata": {},
   "source": [
    "          id       country managed_by  fulfill_via vendor_inco_term  ... first_line_designation  weight_kilograms freight_cost_usd freight_cost_groups line_item_insurance_usd\n",
    "0    36203.0       Nigeria   PMO - US  Direct Drop              EXW  ...                    Yes            1426.0         33279.83           expensive                  373.83\n",
    "1    30998.0      Botswana   PMO - US  Direct Drop              EXW  ...                    Yes              10.0           559.89          reasonable                    1.72\n",
    "2    69871.0       Vietnam   PMO - US  Direct Drop              EXW  ...                    Yes            3723.0         19056.13           expensive                  181.57\n",
    "3    17648.0  South Africa   PMO - US  Direct Drop              DDP  ...                    Yes            7698.0         11372.23           expensive                  779.41\n",
    "4     5647.0        Uganda   PMO - US  Direct Drop              EXW  ...                    Yes              56.0           360.00          reasonable                    0.01\n",
    "..       ...           ...        ...          ...              ...  ...                    ...               ...              ...                 ...                     ...\n",
    "995  13608.0        Uganda   PMO - US  Direct Drop              DDP  ...                    Yes              43.0           199.00          reasonable                   12.72\n",
    "996  80394.0    Congo, DRC   PMO - US  Direct Drop              EXW  ...                    Yes              99.0          2162.55          reasonable                   13.10\n",
    "997  61675.0        Zambia   PMO - US  Direct Drop              EXW  ...                    Yes             881.0         14019.38           expensive                  210.49\n",
    "998  39182.0  South Africa   PMO - US  Direct Drop              DDP  ...                    Yes           16234.0         14439.17           expensive                 1421.41\n",
    "999   5645.0      Botswana   PMO - US  Direct Drop              EXW  ...                    Yes              46.0          1028.18          reasonable                   23.04\n",
    "\n",
    "[1000 rows x 27 columns]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee76a0a0",
   "metadata": {},
   "source": [
    "# Print the late_shipments dataset\n",
    "print(late_shipments)\n",
    "\n",
    "# Calculate the proportion of late shipments\n",
    "late_prop_samp = (late_shipments['late'] == 'Yes').mean()\n",
    "\n",
    "# Print the results\n",
    "print(late_prop_samp)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e85fa46",
   "metadata": {},
   "source": [
    "# Hypothesize that the proportion is 6%\n",
    "late_prop_hyp = 0.06\n",
    "\n",
    "# Calculate the standard error\n",
    "std_error = np.std(late_shipments_boot_distn, ddof=1)\n",
    "\n",
    "# Find z-score of late_prop_samp\n",
    "z_score = (late_prop_samp - late_prop_hyp) / std_error\n",
    "\n",
    "# Print z_score\n",
    "print(z_score)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e26e0944",
   "metadata": {},
   "source": [
    "0.13353771933071554"
   ]
  },
  {
   "cell_type": "raw",
   "id": "874165e4",
   "metadata": {},
   "source": [
    "# Calculate the z-score of late_prop_samp\n",
    "z_score = (late_prop_samp - late_prop_hyp) / std_error\n",
    "\n",
    "# Calculate the p-value\n",
    "p_value = 1 - norm.cdf(z_score)\n",
    "                 \n",
    "# Print the p-value\n",
    "print(p_value) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "f87dad47",
   "metadata": {},
   "source": [
    "0.4468840678346485"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc684a83",
   "metadata": {},
   "source": [
    "# Calculate 95% confidence interval using quantile method\n",
    "lower = np.quantile(late_shipments_boot_distn, 0.025)\n",
    "upper = np.quantile(late_shipments_boot_distn, 0.975)\n",
    "\n",
    "# Print the confidence interval\n",
    "print((lower, upper))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "04429cef",
   "metadata": {},
   "source": [
    "(0.047, 0.076)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1f96486",
   "metadata": {},
   "source": [
    "# Calculate the numerator of the test statistic\n",
    "numerator = xbar_no - xbar_yes\n",
    "\n",
    "# Calculate the denominator of the test statistic\n",
    "denominator = np.sqrt((s_no**2 / n_no) + (s_yes**2 / n_yes))\n",
    "\n",
    "# Calculate the test statistic\n",
    "t_stat = numerator / denominator\n",
    "\n",
    "# Print the test statistic\n",
    "print(t_stat)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "64654219",
   "metadata": {},
   "source": [
    "-2.3936661778766433"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0aa1af6a",
   "metadata": {},
   "source": [
    "# Calculate the degrees of freedom\n",
    "degrees_of_freedom = n_no + n_yes - 2\n",
    "\n",
    "# Calculate the p-value from the test stat\n",
    "p_value = t.cdf(t_stat, df=degrees_of_freedom)\n",
    "\n",
    "# Print the p_value\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675749ec",
   "metadata": {},
   "source": [
    "0.008432382146249523"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebeee650",
   "metadata": {},
   "source": [
    "# Calculate the differences from 2012 to 2016\n",
    "sample_dem_data['diff'] = sample_dem_data['dem_percent_12'] - sample_dem_data['dem_percent_16']\n",
    "\n",
    "# Print sample_dem_data\n",
    "print(sample_dem_data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "af765e9f",
   "metadata": {},
   "source": [
    "       state       county  dem_percent_12  dem_percent_16    diff\n",
    "    0    Alabama      Bullock          76.306          74.947   1.359\n",
    "    1    Alabama      Chilton          19.454          15.847   3.606\n",
    "    2    Alabama         Clay          26.674          18.675   7.999\n",
    "    3    Alabama      Cullman          14.662          10.028   4.634\n",
    "    4    Alabama     Escambia          36.916          31.021   5.895\n",
    "    ..       ...          ...             ...             ...     ...\n",
    "    495  Wyoming        Uinta          19.065          14.191   4.874\n",
    "    496  Wyoming     Washakie          20.132          13.949   6.183\n",
    "    497   Alaska   District 3          33.515          16.301  17.214\n",
    "    498   Alaska  District 18          61.284          52.810   8.474\n",
    "    499   Alaska  District 24          42.914          39.405   3.509\n",
    "    \n",
    "    [500 rows x 5 columns]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c473fdb",
   "metadata": {},
   "source": [
    "# Calculate the differences from 2012 to 2016\n",
    "sample_dem_data['diff'] = sample_dem_data['dem_percent_12'] - sample_dem_data['dem_percent_16']\n",
    "\n",
    "# Find the mean of the diff column\n",
    "xbar_diff = sample_dem_data['diff'].mean()\n",
    "\n",
    "# Print xbar_diff\n",
    "print(xbar_diff)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf05012b",
   "metadata": {},
   "source": [
    "6.829312660106834"
   ]
  },
  {
   "cell_type": "raw",
   "id": "659c48ac",
   "metadata": {},
   "source": [
    "# Calculate the differences from 2012 to 2016\n",
    "sample_dem_data['diff'] = sample_dem_data['dem_percent_12'] - sample_dem_data['dem_percent_16']\n",
    "\n",
    "# Find the mean of the diff column\n",
    "xbar_diff = sample_dem_data['diff'].mean()\n",
    "\n",
    "# Find the standard deviation of the diff column\n",
    "s_diff = sample_dem_data['diff'].std()\n",
    "\n",
    "# Print s_diff\n",
    "print(s_diff)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "966d547e",
   "metadata": {},
   "source": [
    "5.040139140132317"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6860042e",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the differences from 2012 to 2016\n",
    "sample_dem_data['diff'] = sample_dem_data['dem_percent_12'] - sample_dem_data['dem_percent_16']\n",
    "\n",
    "# Find the mean of the diff column\n",
    "xbar_diff = sample_dem_data['diff'].mean()\n",
    "\n",
    "# Find the standard deviation of the diff column\n",
    "s_diff = sample_dem_data['diff'].std()\n",
    "\n",
    "# Plot a histogram of diff with 20 bins\n",
    "sample_dem_data['diff'].hist(bins=20)\n",
    "plt.xlabel('Difference in Democratic Vote Percentage')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Differences in Democratic Vote Percentages (2012 vs 2016)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b12332a2",
   "metadata": {},
   "source": [
    "import pingouin as pg\n",
    "\n",
    "# Conduct a t-test on diff\n",
    "test_results = pg.ttest(x=sample_dem_data['diff'], y=0, alternative='two-sided')\n",
    "\n",
    "# Print the test results\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e28c704",
   "metadata": {},
   "source": [
    "              T  dof alternative       p-val         CI95%  cohen-d        BF10  power\n",
    "    T-test  30.298  499   two-sided  3.601e-115  [6.39, 7.27]    1.355  2.246e+111    1.0"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83612723",
   "metadata": {},
   "source": [
    "import pingouin as pg\n",
    "\n",
    "# Conduct a t-test on diff\n",
    "test_results = pg.ttest(x=sample_dem_data['diff'], \n",
    "                        y=0, \n",
    "                        alternative=\"two-sided\")\n",
    "\n",
    "# Conduct a paired t-test on dem_percent_12 and dem_percent_16\n",
    "paired_test_results = pg.ttest(x=sample_dem_data['dem_percent_12'], \n",
    "                               y=sample_dem_data['dem_percent_16'], \n",
    "                               paired=True, \n",
    "                               alternative=\"two-sided\")\n",
    "\n",
    "# Print the paired test results\n",
    "print(paired_test_results)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "137e9641",
   "metadata": {},
   "source": [
    "# Calculate the mean pack_price for each shipment_mode\n",
    "xbar_pack_by_mode = late_shipments.groupby('shipment_mode')['pack_price'].mean()\n",
    "\n",
    "# Print the grouped means\n",
    "print(xbar_pack_by_mode)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99a2ddac",
   "metadata": {},
   "source": [
    "    shipment_mode\n",
    "    Air            39.712\n",
    "    Air Charter     4.227\n",
    "    Ocean           6.432\n",
    "    Name: pack_price, dtype: float64"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83b24357",
   "metadata": {},
   "source": [
    "# Calculate the mean pack_price for each shipment_mode\n",
    "xbar_pack_by_mode = late_shipments.groupby(\"shipment_mode\")['pack_price'].mean()\n",
    "\n",
    "# Calculate the standard deviation of the pack_price for each shipment_mode\n",
    "s_pack_by_mode = late_shipments.groupby(\"shipment_mode\")['pack_price'].std()\n",
    "\n",
    "# Print the grouped standard deviations\n",
    "print(s_pack_by_mode)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab174b43",
   "metadata": {},
   "source": [
    "    shipment_mode\n",
    "    Air            48.933\n",
    "    Air Charter     0.993\n",
    "    Ocean           5.303\n",
    "    Name: pack_price, dtype: float64"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a008d468",
   "metadata": {},
   "source": [
    "# Calculate the mean pack_price for each shipment_mode\n",
    "xbar_pack_by_mode = late_shipments.groupby(\"shipment_mode\")['pack_price'].mean()\n",
    "\n",
    "# Calculate the standard deviation of the pack_price for each shipment_mode\n",
    "s_pack_by_mode = late_shipments.groupby(\"shipment_mode\")['pack_price'].std()\n",
    "\n",
    "# Boxplot of shipment_mode vs. pack_price\n",
    "sns.boxplot(x=\"pack_price\", y=\"shipment_mode\", data=late_shipments)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be47484c",
   "metadata": {},
   "source": [
    "import pingouin as pg\n",
    "\n",
    "# Run an ANOVA on late_shipments investigating 'pack_price' between the groups of 'shipment_mode'\n",
    "anova_results = pg.anova(dv='pack_price', between='shipment_mode', data=late_shipments)\n",
    "\n",
    "# Print the ANOVA results\n",
    "print(anova_results)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "223232da",
   "metadata": {},
   "source": [
    "              Source  ddof1  ddof2       F      p-unc    np2\n",
    "    0  shipment_mode      2    997  21.865  5.089e-10  0.042"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3687b03",
   "metadata": {},
   "source": [
    "import pingouin as pg\n",
    "\n",
    "# Perform pairwise t-tests on pack_price grouped by shipment_mode\n",
    "pairwise_results = pg.pairwise_ttests(dv='pack_price', between='shipment_mode', data=late_shipments, padjust='none')\n",
    "\n",
    "# Print the pairwise t-test results\n",
    "print(pairwise_results)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "add6b542",
   "metadata": {},
   "source": [
    "            Contrast            A            B  Paired  Parametric  ...      dof  alternative      p-unc       BF10 hedges\n",
    "    0  shipment_mode          Air  Air Charter   False        True  ...  600.686    two-sided  8.748e-75  5.809e+76  0.727\n",
    "    1  shipment_mode          Air        Ocean   False        True  ...  986.980    two-sided  6.935e-71  1.129e+67  0.711\n",
    "    2  shipment_mode  Air Charter        Ocean   False        True  ...   35.615    two-sided  3.123e-03     15.277 -0.424\n",
    "    \n",
    "    [3 rows x 11 columns]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4935d077",
   "metadata": {},
   "source": [
    "import pingouin as pg\n",
    "\n",
    "# Modify the pairwise t-tests to use Bonferroni p-value adjustment\n",
    "pairwise_results = pg.pairwise_tests(data=late_shipments, \n",
    "                                     dv=\"pack_price\",\n",
    "                                     between=\"shipment_mode\",\n",
    "                                     padjust=\"bonf\")\n",
    "\n",
    "# Print pairwise_results\n",
    "print(pairwise_results)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e63ab61c",
   "metadata": {},
   "source": [
    "            Contrast            A            B  Paired  Parametric  ...      p-unc     p-corr p-adjust       BF10  hedges\n",
    "    0  shipment_mode          Air  Air Charter   False        True  ...  8.748e-75  2.625e-74     bonf  5.809e+76   0.727\n",
    "    1  shipment_mode          Air        Ocean   False        True  ...  6.935e-71  2.080e-70     bonf  1.129e+67   0.711\n",
    "    2  shipment_mode  Air Charter        Ocean   False        True  ...  3.123e-03  9.369e-03     bonf     15.277  -0.424\n",
    "    \n",
    "    [3 rows x 13 columns]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ae7a417",
   "metadata": {},
   "source": [
    "# Hypothesize that the proportion of late shipments is 6%\n",
    "p_0 = 0.06\n",
    "\n",
    "# Calculate the sample proportion of late shipments\n",
    "p_hat = (late_shipments['late'] == 'Yes').mean()\n",
    "\n",
    "# Calculate the sample size\n",
    "n = len(late_shipments)\n",
    "\n",
    "# Print p_hat and n\n",
    "print(p_hat, n)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "abcdc02a",
   "metadata": {},
   "source": [
    " 0.061 1000"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b013b105",
   "metadata": {},
   "source": [
    "# Hypothesize that the proportion of late shipments is 6%\n",
    "p_0 = 0.06\n",
    "\n",
    "# Calculate the sample proportion of late shipments\n",
    "p_hat = (late_shipments['late'] == \"Yes\").mean()\n",
    "\n",
    "# Calculate the sample size\n",
    "n = len(late_shipments)\n",
    "\n",
    "# Calculate the numerator and denominator of the test statistic\n",
    "numerator = p_hat - p_0\n",
    "denominator = np.sqrt((p_0 * (1 - p_0)) / n)\n",
    "\n",
    "# Calculate the test statistic\n",
    "z_score = numerator / denominator\n",
    "\n",
    "# Print the result\n",
    "print(z_score)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4185259b",
   "metadata": {},
   "source": [
    "    0.13315591032282698"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e29e3922",
   "metadata": {},
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# Hypothesize that the proportion of late shipments is 6%\n",
    "p_0 = 0.06\n",
    "\n",
    "# Calculate the sample proportion of late shipments\n",
    "p_hat = (late_shipments['late'] == \"Yes\").mean()\n",
    "\n",
    "# Calculate the sample size\n",
    "n = len(late_shipments)\n",
    "\n",
    "# Calculate the numerator and denominator of the test statistic\n",
    "numerator = p_hat - p_0\n",
    "denominator = np.sqrt(p_0 * (1 - p_0) / n)\n",
    "\n",
    "# Calculate the test statistic\n",
    "z_score = numerator / denominator\n",
    "\n",
    "# Calculate the p-value from the z-score (right-tailed test)\n",
    "p_value = 1 - norm.cdf(z_score)\n",
    "\n",
    "# Print the p-value\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aba43fb8",
   "metadata": {},
   "source": [
    "    0.44703503936503364"
   ]
  },
  {
   "cell_type": "raw",
   "id": "596651b1",
   "metadata": {},
   "source": [
    "# Calculate the pooled estimate of the population proportion\n",
    "p_hat = (p_hats['expensive'] * ns['expensive'] + p_hats['reasonable'] * ns['reasonable']) / (ns['expensive'] + ns['reasonable'])\n",
    "\n",
    "# Print the result\n",
    "print(p_hat)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "13785de0",
   "metadata": {},
   "source": [
    "    late\n",
    "    Yes    0.061\n",
    "    Name: late, dtype: float64"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b717e35b",
   "metadata": {},
   "source": [
    "# Calculate the pooled estimate of the population proportion\n",
    "p_hat = (p_hats[\"reasonable\"] * ns[\"reasonable\"] + p_hats[\"expensive\"] * ns[\"expensive\"]) / (ns[\"reasonable\"] + ns[\"expensive\"])\n",
    "\n",
    "# Calculate p_hat times (1 - p_hat)\n",
    "p_hat_times_not_p_hat = p_hat * (1 - p_hat)\n",
    "\n",
    "# Divide this by each of the sample sizes and then sum\n",
    "p_hat_times_not_p_hat_over_ns = p_hat_times_not_p_hat * (1 / ns[\"reasonable\"] + 1 / ns[\"expensive\"])\n",
    "\n",
    "# Calculate the standard error\n",
    "std_error = np.sqrt(p_hat_times_not_p_hat_over_ns)\n",
    "\n",
    "# Print the result\n",
    "print(std_error)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e9ac4ba",
   "metadata": {},
   "source": [
    "    late\n",
    "    Yes    0.015\n",
    "    Name: late, dtype: float64"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c3d5fcf6",
   "metadata": {},
   "source": [
    "# Calculate the pooled estimate of the population proportion\n",
    "p_hat = (p_hats[\"reasonable\"] * ns[\"reasonable\"] + p_hats[\"expensive\"] * ns[\"expensive\"]) / (ns[\"reasonable\"] + ns[\"expensive\"])\n",
    "\n",
    "# Calculate p_hat one minus p_hat\n",
    "p_hat_times_not_p_hat = p_hat * (1 - p_hat)\n",
    "\n",
    "# Divide this by each of the sample sizes and then sum\n",
    "p_hat_times_not_p_hat_over_ns = p_hat_times_not_p_hat / ns[\"expensive\"] + p_hat_times_not_p_hat / ns[\"reasonable\"]\n",
    "\n",
    "# Calculate the standard error\n",
    "std_error = np.sqrt(p_hat_times_not_p_hat_over_ns)\n",
    "\n",
    "# Calculate the z-score\n",
    "z_score = (p_hats[\"expensive\"] - p_hats[\"reasonable\"]) / std_error\n",
    "\n",
    "# Print z_score\n",
    "print(z_score)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4d92cb76",
   "metadata": {},
   "source": [
    "late\n",
    "Yes    3.119\n",
    "Name: late, dtype: float64"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f2419ad1",
   "metadata": {},
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# Calculate the pooled estimate of the population proportion\n",
    "p_hat = (p_hats[\"reasonable\"] * ns[\"reasonable\"] + p_hats[\"expensive\"] * ns[\"expensive\"]) / (ns[\"reasonable\"] + ns[\"expensive\"])\n",
    "\n",
    "# Calculate p_hat one minus p_hat\n",
    "p_hat_times_not_p_hat = p_hat * (1 - p_hat)\n",
    "\n",
    "# Divide this by each of the sample sizes and then sum\n",
    "p_hat_times_not_p_hat_over_ns = p_hat_times_not_p_hat / ns[\"expensive\"] + p_hat_times_not_p_hat / ns[\"reasonable\"]\n",
    "\n",
    "# Calculate the standard error\n",
    "std_error = np.sqrt(p_hat_times_not_p_hat_over_ns)\n",
    "\n",
    "# Calculate the z-score\n",
    "z_score = (p_hats[\"expensive\"] - p_hats[\"reasonable\"]) / std_error\n",
    "\n",
    "# Calculate the p-value from the z-score (right-tailed test)\n",
    "p_value = 1 - norm.cdf(z_score)\n",
    "\n",
    "# Print p_value\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f288777d",
   "metadata": {},
   "source": [
    "[0.00090721]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b421992",
   "metadata": {},
   "source": [
    "# Count the late column values for each freight_cost_group\n",
    "late_by_freight_cost_group = late_shipments.groupby('freight_cost_group')['late'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(late_by_freight_cost_group)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d16140da",
   "metadata": {},
   "source": [
    "    freight_cost_group  late\n",
    "    expensive           No      500\n",
    "                        Yes      45\n",
    "    reasonable          No      439\n",
    "                        Yes      16\n",
    "    Name: late, dtype: int64"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9627003c",
   "metadata": {},
   "source": [
    "# Count the late column values for each freight_cost_group\n",
    "late_by_freight_cost_group = late_shipments.groupby(\"freight_cost_group\")['late'].value_counts()\n",
    "\n",
    "# Create an array of the \"Yes\" counts for each freight_cost_group\n",
    "success_counts = np.array([\n",
    "    late_by_freight_cost_group['expensive']['Yes'], \n",
    "    late_by_freight_cost_group['reasonable']['Yes']\n",
    "])\n",
    "\n",
    "# Create an array of the total number of rows in each freight_cost_group\n",
    "n = np.array([\n",
    "    late_by_freight_cost_group['expensive'].sum(), \n",
    "    late_by_freight_cost_group['reasonable'].sum()\n",
    "])\n",
    "\n",
    "# Run a z-test on the two proportions\n",
    "stat, p_value = proportions_ztest(success_counts, n, alternative='larger')\n",
    "\n",
    "# Print the results\n",
    "print(stat, p_value)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3aeaa595",
   "metadata": {},
   "source": [
    "3.1190401865206128 0.0009072060637051224"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f0e32b0",
   "metadata": {},
   "source": [
    "# Proportion of freight_cost_group grouped by vendor_inco_term\n",
    "props = late_shipments.groupby('vendor_inco_term')['freight_cost_group'].value_counts(normalize=True)\n",
    "\n",
    "# Print props\n",
    "print(props)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5d5c924",
   "metadata": {},
   "source": [
    "    vendor_inco_term  freight_cost_group\n",
    "    CIP               reasonable            0.607\n",
    "                      expensive             0.393\n",
    "    DDP               expensive             0.550\n",
    "                      reasonable            0.450\n",
    "    EXW               expensive             0.587\n",
    "                      reasonable            0.413\n",
    "    FCA               reasonable            0.658\n",
    "                      expensive             0.342\n",
    "    Name: freight_cost_group, dtype: float64"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c88acdd",
   "metadata": {},
   "source": [
    "# Proportion of freight_cost_group grouped by vendor_inco_term\n",
    "props = late_shipments.groupby('vendor_inco_term')['freight_cost_group'].value_counts(normalize=True)\n",
    "\n",
    "# Convert props to wide format\n",
    "wide_props = props.unstack()\n",
    "\n",
    "# Print wide_props\n",
    "print(wide_props)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "01e7eb8d",
   "metadata": {},
   "source": [
    "    freight_cost_group  expensive  reasonable\n",
    "    vendor_inco_term                         \n",
    "    CIP                     0.393       0.607\n",
    "    DDP                     0.550       0.450\n",
    "    EXW                     0.587       0.413\n",
    "    FCA                     0.342       0.658"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a1734a7",
   "metadata": {},
   "source": [
    "# Proportion of freight_cost_group grouped by vendor_inco_term\n",
    "props = late_shipments.groupby('vendor_inco_term')['freight_cost_group'].value_counts(normalize=True)\n",
    "\n",
    "# Convert props to wide format\n",
    "wide_props = props.unstack()\n",
    "\n",
    "# Proportional stacked bar plot of freight_cost_group vs. vendor_inco_term\n",
    "wide_props.plot(kind='bar', stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55e7a241",
   "metadata": {},
   "source": [
    "import pingouin as pg\n",
    "\n",
    "# Proportion of freight_cost_group grouped by vendor_inco_term\n",
    "props = late_shipments.groupby('vendor_inco_term')['freight_cost_group'].value_counts(normalize=True)\n",
    "\n",
    "# Convert props to wide format\n",
    "wide_props = props.unstack()\n",
    "\n",
    "# Proportional stacked bar plot of freight_cost_group vs. vendor_inco_term\n",
    "wide_props.plot(kind='bar', stacked=True)\n",
    "plt.show()\n",
    "\n",
    "# Perform chi-square test of independence\n",
    "chi2_results = pg.chi2_independence(late_shipments, x='freight_cost_group', y='vendor_inco_term')\n",
    "\n",
    "# Extract the expected, observed, and stats from the chi2_results tuple\n",
    "expected, observed, stats = chi2_results\n",
    "\n",
    "# Print the Pearson's chi-square test result\n",
    "print(stats[stats['test'] == 'pearson'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1266fab",
   "metadata": {},
   "source": [
    "          test  lambda    chi2  dof       pval  cramer  power\n",
    "    0  pearson     1.0  28.941  3.0  2.304e-06    0.17  0.998"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9a38692",
   "metadata": {},
   "source": [
    "# Find the number of rows in late_shipments\n",
    "n_total = len(late_shipments)\n",
    "\n",
    "# Print n_total\n",
    "print(n_total)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5d2df914",
   "metadata": {},
   "source": [
    "    999"
   ]
  },
  {
   "cell_type": "raw",
   "id": "86e8ffd7",
   "metadata": {},
   "source": [
    "# Find the number of rows in late_shipments\n",
    "n_total = len(late_shipments)\n",
    "\n",
    "# Create n column that is prop column * n_total\n",
    "hypothesized['n'] = hypothesized['prop'] * n_total\n",
    "\n",
    "# Print the modified hypothesized DataFrame\n",
    "print(hypothesized)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c9a4e62",
   "metadata": {},
   "source": [
    "      vendor_inco_term  prop       n\n",
    "    1              CIP  0.05   49.95\n",
    "    2              DDP  0.10   99.90\n",
    "    0              EXW  0.75  749.25\n",
    "    3              FCA  0.10   99.90"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5aef849d",
   "metadata": {},
   "source": [
    "# Find the number of rows in late_shipments\n",
    "n_total = len(late_shipments)\n",
    "\n",
    "# Create n column that is prop column * n_total\n",
    "hypothesized[\"n\"] = hypothesized[\"prop\"] * n_total\n",
    "\n",
    "# Plot a red bar graph of n vs. vendor_inco_term for incoterm_counts\n",
    "plt.bar(incoterm_counts['vendor_inco_term'], incoterm_counts['n'], color='red')\n",
    "plt.xlabel(\"Vendor Incoterm\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "497b8a03",
   "metadata": {},
   "source": [
    "# Find the number of rows in late_shipments\n",
    "n_total = len(late_shipments)\n",
    "\n",
    "# Create n column that is prop column * n_total\n",
    "hypothesized[\"n\"] = hypothesized[\"prop\"] * n_total\n",
    "\n",
    "# Plot a red bar graph of n vs. vendor_inco_term for incoterm_counts\n",
    "plt.bar(incoterm_counts['vendor_inco_term'], incoterm_counts['n'], color=\"red\", label=\"Observed\")\n",
    "\n",
    "# Add a blue bar plot for the hypothesized counts\n",
    "plt.bar(hypothesized['vendor_inco_term'], hypothesized['n'], color=\"blue\", alpha=0.5, label=\"Hypothesized\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "abfb3924",
   "metadata": {},
   "source": [
    "from scipy.stats import chisquare\n",
    "\n",
    "# Perform a goodness of fit test on the incoterm counts n\n",
    "gof_test = chisquare(f_obs=incoterm_counts['n'], f_exp=hypothesized['n'])\n",
    "\n",
    "# Print gof_test results\n",
    "print(gof_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a545935d",
   "metadata": {},
   "source": [
    "Power_divergenceResult(statistic=2.3633633633633613, pvalue=0.5004909543758689)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e367db60",
   "metadata": {},
   "source": [
    "# Count the freight_cost_group values\n",
    "counts = late_shipments['freight_cost_group'].value_counts()\n",
    "\n",
    "# Print the result\n",
    "print(counts)\n",
    "\n",
    "# Inspect whether the counts are big enough (e.g., for a two-sample t-test, typically at least 30 observations in each group)\n",
    "print((counts >= 30).all())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2de3958",
   "metadata": {},
   "source": [
    "    expensive     545\n",
    "    reasonable    454\n",
    "    Name: freight_cost_group, dtype: int64\n",
    "    True"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4e8b306",
   "metadata": {},
   "source": [
    "# Count the late values\n",
    "counts = late_shipments['late'].value_counts()\n",
    "\n",
    "# Print the result\n",
    "print(counts)\n",
    "\n",
    "# Inspect whether the counts are big enough (e.g., for a one-sample proportion test, typically at least 10 in each category)\n",
    "print((counts >= 10).all())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "607ce52c",
   "metadata": {},
   "source": [
    "    No     938\n",
    "    Yes     61\n",
    "    Name: late, dtype: int64\n",
    "    True"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9bf57e80",
   "metadata": {},
   "source": [
    "# Count the values of freight_cost_group grouped by vendor_inco_term\n",
    "counts = late_shipments.groupby('vendor_inco_term')['freight_cost_group'].value_counts()\n",
    "\n",
    "# Print the result\n",
    "print(counts)\n",
    "\n",
    "# Inspect whether the counts are big enough (e.g., for a chi-square test, typically each expected count should be at least 5)\n",
    "print((counts >= 5).all())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "31c625c5",
   "metadata": {},
   "source": [
    " vendor_inco_term  freight_cost_group\n",
    "    CIP               reasonable             34\n",
    "                      expensive              22\n",
    "    DDP               expensive              55\n",
    "                      reasonable             45\n",
    "    EXW               expensive             430\n",
    "                      reasonable            302\n",
    "    FCA               reasonable             73\n",
    "                      expensive              38\n",
    "    Name: freight_cost_group, dtype: int64\n",
    "    True"
   ]
  },
  {
   "cell_type": "raw",
   "id": "36ff48b6",
   "metadata": {},
   "source": [
    "# Count the shipment_mode values\n",
    "counts = late_shipments['shipment_mode'].value_counts()\n",
    "\n",
    "# Print the result\n",
    "print(counts)\n",
    "\n",
    "# Inspect whether the counts are big enough (e.g., for an ANOVA test, typically at least 30 observations in each group)\n",
    "print((counts >= 30).all())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5242228a",
   "metadata": {},
   "source": [
    "    Air            905\n",
    "    Ocean           88\n",
    "    Air Charter      6\n",
    "    Name: shipment_mode, dtype: int64\n",
    "    False"
   ]
  },
  {
   "cell_type": "raw",
   "id": "548077a1",
   "metadata": {},
   "source": [
    "import pingouin as pg\n",
    "\n",
    "# Conduct a paired t-test on dem_percent_12 and dem_percent_16\n",
    "paired_test_results = pg.ttest(x=sample_dem_data['dem_percent_12'], \n",
    "                               y=sample_dem_data['dem_percent_16'], \n",
    "                               paired=True, \n",
    "                               alternative='two-sided')\n",
    "\n",
    "# Print paired t-test results\n",
    "print(paired_test_results)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b243c7f",
   "metadata": {},
   "source": [
    "                 T  dof alternative       p-val         CI95%  cohen-d        BF10  power\n",
    "    T-test  30.298  499   two-sided  3.601e-115  [6.39, 7.27]    0.454  2.246e+111    1.0"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb245580",
   "metadata": {},
   "source": [
    "import pingouin as pg\n",
    "\n",
    "# Select the weight_kilograms and late columns\n",
    "weight_vs_late = late_shipments[['weight_kilograms', 'late']]\n",
    "\n",
    "# Convert weight_vs_late into wide format\n",
    "weight_vs_late_wide = weight_vs_late.pivot(columns='late', values='weight_kilograms')\n",
    "\n",
    "# Run a two-sided Wilcoxon-Mann-Whitney test on weight_kilograms vs. late\n",
    "wmw_test = pg.mwu(x=weight_vs_late_wide['Yes'], \n",
    "                  y=weight_vs_late_wide['No'], \n",
    "                  alternative='two-sided')\n",
    "\n",
    "# Print the test results\n",
    "print(wmw_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "651e2972",
   "metadata": {},
   "source": [
    "       U-val alternative      p-val    RBC   CLES\n",
    "MWU  38145.0   two-sided  1.371e-05 -0.332  0.666"
   ]
  },
  {
   "cell_type": "raw",
   "id": "924e37f2",
   "metadata": {},
   "source": [
    "import pingouin as pg\n",
    "\n",
    "# Run a Kruskal-Wallis test on weight_kilograms vs. shipment_mode\n",
    "kw_test = pg.kruskal(data=late_shipments, dv='weight_kilograms', between='shipment_mode')\n",
    "\n",
    "# Print the results\n",
    "print(kw_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec2923c7",
   "metadata": {},
   "source": [
    "                Source  ddof1        H      p-unc\n",
    "Kruskal  shipment_mode      2  125.097  6.849e-28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a7699",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
